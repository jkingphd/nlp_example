{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import Ridge\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          0  article  random   test  0.0  1.0  0.1  0  \n",
       "3          1  article  random  train  0.0  2.0  0.6  0  \n",
       "4          1  article  random   test -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sql.connect('../data/toxic.db') as conn:\n",
    "    df = pd.read_sql_query('''select * from toxic''', conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into two seperate dataframes: df_train and df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>\"\\n\\n\\nI fixed the link; I also removed \"\"home...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>\"If they are \"\"indisputable\"\" then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "3  37330.0  \"\\n\\n\\nI fixed the link; I also removed \"\"home...  2002   \n",
       "4  37346.0  \"If they are \"\"indisputable\"\" then why does th...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          1  article  random  train  0.0  2.0  0.6  0  \n",
       "3          1  article  random  train -1.0  1.0  0.1  0  \n",
       "4          1  article  random  train -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['split'] == 'train'].copy().reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['split'] == 'test'].copy().reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab our \"best\" model from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return re.findall(r'[a-z0-9]+', text.lower())\n",
    "\n",
    "gs = load('../results/gs_cv_sgd.joblib')\n",
    "pipe = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make things easier, let's compute probabilities for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y    y_prob  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  0.244198  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  0.172840  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  0.003700  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  0.008976  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  0.007818  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['y_prob'] = pipe.predict_proba(df_test['comment'])[:,1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global surrogates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many NLP models use complicated neural network architecture that don't exactly lend themselves well to interpretation. A global surrogate is an interpretable model (e.g., decision tree, logistic regression, k-nearest neighbors, etc.) that is trained on the output of the _true_ model. In effect, it tries to distill the complex model into a simpler one, which can have benefits for deployment as well. Our \"best\" model is a linear model, so this is a bit more direct that the process would normally be. Let's start by looking at the tokens that are most important for predicting each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.485310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0</td>\n",
       "      <td>0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 00</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 005</td>\n",
       "      <td>-0.007528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 01</td>\n",
       "      <td>-0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token    weight\n",
       "0      0 -0.485310\n",
       "1    0 0  0.039417\n",
       "2   0 00 -0.000088\n",
       "3  0 005 -0.007528\n",
       "4   0 01 -0.002821"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pipe.named_steps['vect'].get_feature_names() # Note, NOT the same as vocabulary_\n",
    "weights = pipe.named_steps['clf'].coef_[0]\n",
    "df_model = pd.DataFrame({'token':tokens, 'weight':weights})\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463216</th>\n",
       "      <td>thanks</td>\n",
       "      <td>-1.575386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127997</th>\n",
       "      <td>cool you</td>\n",
       "      <td>-1.079754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463188</th>\n",
       "      <td>thank you</td>\n",
       "      <td>-1.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220356</th>\n",
       "      <td>hey hey</td>\n",
       "      <td>-0.978156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58988</th>\n",
       "      <td>are cool</td>\n",
       "      <td>-0.958368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463160</th>\n",
       "      <td>thank</td>\n",
       "      <td>-0.863174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189578</th>\n",
       "      <td>for your</td>\n",
       "      <td>-0.836592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130100</th>\n",
       "      <td>could you</td>\n",
       "      <td>-0.775153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393418</th>\n",
       "      <td>regards</td>\n",
       "      <td>-0.771566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228178</th>\n",
       "      <td>http en</td>\n",
       "      <td>-0.759324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token    weight\n",
       "463216     thanks -1.575386\n",
       "127997   cool you -1.079754\n",
       "463188  thank you -1.015618\n",
       "220356    hey hey -0.978156\n",
       "58988    are cool -0.958368\n",
       "463160      thank -0.863174\n",
       "189578   for your -0.836592\n",
       "130100  could you -0.775153\n",
       "393418    regards -0.771566\n",
       "228178    http en -0.759324"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88865</th>\n",
       "      <td>block block</td>\n",
       "      <td>12.789651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315629</th>\n",
       "      <td>nipple nipple</td>\n",
       "      <td>11.052719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315628</th>\n",
       "      <td>nipple</td>\n",
       "      <td>10.774228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459260</th>\n",
       "      <td>teabag</td>\n",
       "      <td>9.681863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97787</th>\n",
       "      <td>buttsecks</td>\n",
       "      <td>7.755658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540505</th>\n",
       "      <td>wikipedia hi</td>\n",
       "      <td>5.545768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220792</th>\n",
       "      <td>hi wikipedia</td>\n",
       "      <td>5.399690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195137</th>\n",
       "      <td>fuck</td>\n",
       "      <td>4.016078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109999</th>\n",
       "      <td>chester</td>\n",
       "      <td>3.474630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500501</th>\n",
       "      <td>tommy2010</td>\n",
       "      <td>3.472154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                token     weight\n",
       "88865     block block  12.789651\n",
       "315629  nipple nipple  11.052719\n",
       "315628         nipple  10.774228\n",
       "459260         teabag   9.681863\n",
       "97787       buttsecks   7.755658\n",
       "540505   wikipedia hi   5.545768\n",
       "220792   hi wikipedia   5.399690\n",
       "195137           fuck   4.016078\n",
       "109999        chester   3.474630\n",
       "500501      tommy2010   3.472154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual examples\n",
    "A counterfactual explanation of a prediction describes the smallest change to the prediction instance that results in a change to a predefined output. In the context of this problem, the smallest change that induces a change from toxic to non-toxic or vice-versa. Of course, defining what constitutes a _small_ change is particularly difficult. Here are a couple basic strategies for generating those examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical comparison \n",
    "We'll start by picking a positive (toxic) example from the test set and finding the _closest_ example from the training set that had a negative (non-toxic) outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>122936921.0</td>\n",
       "      <td>\\n:Are you an idiot? That plot synopsis wasn't...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16289</th>\n",
       "      <td>278071348.0</td>\n",
       "      <td>You're the one who amditted that your edits w...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30518</th>\n",
       "      <td>656766319.0</td>\n",
       "      <td>\\n\\nYour threats don't work, motherfucker. I d...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23007</th>\n",
       "      <td>434447019.0</td>\n",
       "      <td>\\n\\n== Suspected Sockpuppetry ==\\n\\nI suspect ...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9530</th>\n",
       "      <td>154523620.0</td>\n",
       "      <td>\\n\\nI think mucha lucha is the most homosexual...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id                                            comment  year  \\\n",
       "7820   122936921.0  \\n:Are you an idiot? That plot synopsis wasn't...  2007   \n",
       "16289  278071348.0   You're the one who amditted that your edits w...  2009   \n",
       "30518  656766319.0  \\n\\nYour threats don't work, motherfucker. I d...  2015   \n",
       "23007  434447019.0  \\n\\n== Suspected Sockpuppetry ==\\n\\nI suspect ...  2011   \n",
       "9530   154523620.0  \\n\\nI think mucha lucha is the most homosexual...  2007   \n",
       "\n",
       "       logged_in       ns   sample split  min  max  avg  y    y_prob  \n",
       "7820           1     user  blocked  test -2.0  1.0 -1.0  1  0.910260  \n",
       "16289          0  article  blocked  test -1.0  1.0 -0.2  1  0.544424  \n",
       "30518          0     user  blocked  test -2.0  0.0 -1.6  1  0.834805  \n",
       "23007          0     user   random  test -1.0  2.0 -0.1  1  0.974467  \n",
       "9530           1  article  blocked  test -2.0 -1.0 -1.1  1  0.997620  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test_pos = (df_test['y'] == 1) & (df_test['y_prob'] > 0.5)\n",
    "df_test[idx_test_pos].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "comment = df_test.loc[13718]['comment']\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize this comment, vectorize all the negative training instances, and determine which one is the closest to the target comment. We'll start by computing [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) (actually, cosine distance, or 1 - cosine similarity) between the target comment and _all_ training comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_neg = df_train['y'] == 0\n",
    "X_train_neg = pipe.named_steps['vect'].transform(df_train.loc[idx_train_neg, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipe.named_steps['vect'].transform([comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.60\n",
      "Cosine Distance: 0.656\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::::::::::: Okay, found a source, don't know if it's good enough, don't care. It was worth a shot. I apologize for the personal attacks to you, but I'd appreciate it if you wouldn't make sarcastic comments or making fun of what I say. \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_dist = pairwise_distances(X_train_neg, X, metric='cosine').flatten()\n",
    "print('AVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_dist.argmin()][0])\n",
    "print('Cosine Distance: %0.3f' % cosine_dist.min())\n",
    "print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[cosine_dist.argmin()] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Both are clearly talking about sources, but the second is apologetic and less confrontational. Let's look at the closest three comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.656\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::::::::::: Okay, found a source, don't know if it's good enough, don't care. It was worth a shot. I apologize for the personal attacks to you, but I'd appreciate it if you wouldn't make sarcastic comments or making fun of what I say. \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.656\n",
      "<COMMENT>\n",
      "\"\n",
      "\n",
      "== looking for a song ==\n",
      "\n",
      "I am looking for a song that I thought was by a Flock of Seagulls from obviously WAY BACK that goes \"\"Don't Change for you, Don't Change a thing for me. It was kind of punkish but made a point a it popped into my mind if anyone can help me. Thanks so much\"\n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.658\n",
      "<COMMENT>\n",
      " Why do people make weird exception for the title Rabbi? Don't give a person a title that needs a degree that they don't have.\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_dist = pairwise_distances(X_train_neg, X, metric='cosine').flatten()\n",
    "for i in cosine_dist.flatten().argsort()[:3]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_dist.argmin()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_dist[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples don't look particularly relevant. Let's look at the three closest positive (toxic) examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_pos = df_train['y'] == 1\n",
    "X_train_pos = pipe.named_steps['vect'].transform(df_train.loc[idx_train_pos, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.568\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I don't give a flying fuck. block me I Don't care. kiss my goddamn ass. DUSTIN Motherfucking D\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.582\n",
      "<COMMENT>\n",
      "And I don't give a damn.  \n",
      "\n",
      "\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.591\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I AM SO SCARED!!!  PLEASE DON'T BLOCK ME FROM EDITING!  I DON'T KNOW WHAT I'LL DO IF I CAN'T EDIT ARTICLES!  (Actually, this was a sarcastic response to your bullshit warning, you stupid asswipe.  Like I really give a shit.  Block me, you stupid fuck.)\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_dist = pairwise_distances(X_train_pos, X, metric='cosine').flatten()\n",
    "for i in cosine_dist.flatten().argsort()[:3]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[cosine_dist.argmin()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_dist[i])\n",
    "#     print(df_train.loc[idx_train_pos, ['avg']].values[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy counterfactual example\n",
    "Now, instead of mining our training data for counterfactual examples, let's attempt to _create_ one by dropping word occurances from the original text until the score changes. Let's review the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps here are relatively straightforward:\n",
    "1. Using the defined vectorizer, convert the comment to a raw count vector.\n",
    "2. Create a variation for each unique token in the raw count vector, such that each variant has a single token masked.\n",
    "3. Generate a confidence score for each variant.\n",
    "4. Identify the feature that moved the base score the furthest and mask it across all other variants.\n",
    "5. Repeat until confidence score crosses threshold.\n",
    "\n",
    "We'll start by demonstrating a single iteration of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 560571)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero = np.nonzero(X.toarray().flatten())[0] # identify all nonzero elements of the target vector\n",
    "variants = np.repeat(X.toarray(), len(idx_nonzero), axis=0)\n",
    "# for each variant, mask a single feature (token)\n",
    "for i, j in enumerate(idx_nonzero):\n",
    "    variants[i,j] = 0\n",
    "variants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a prediction for each variant and identify which feature was most impactful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing token \"shit\" changes toxic score from 96.8% to 67.4%\n"
     ]
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(variants)[:,1]\n",
    "k = y_prob_var.argmin()\n",
    "print('''Removing token \"%s\" changes toxic score from %0.1f%% to %0.1f%%''' % (tokens[idx_nonzero[k]], 100*y_prob_var[0], 100*y_prob_var[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun stuff. Now let's create a function and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction_cf(comment, tokens, pipe, max_tokens=100):\n",
    "    X = pipe.named_steps['vect'].transform([comment])\n",
    "    y_prob_base = pipe.named_steps['clf'].predict_proba(X)[:,1][0]\n",
    "    idx_nonzero = np.nonzero(X.toarray().flatten())[0]\n",
    "    variants = np.repeat(X.toarray(), len(idx_nonzero), axis=0)\n",
    "    for i,j in enumerate(idx_nonzero):\n",
    "        variants[i,j] = 0\n",
    "    log = [[None, None, y_prob_base]]\n",
    "    for step in tqdm(range(max_tokens), total=float('inf')):\n",
    "        y_prob_var = pipe.named_steps['clf'].predict_proba(variants)[:,1]\n",
    "        k = y_prob_var.argsort()[step]\n",
    "#         print(k, tokens[idx_nonzero[k]], y_prob_var[k])\n",
    "        variants[:,idx_nonzero[k]] = 0\n",
    "        log.append([k, tokens[idx_nonzero[k]], y_prob_var[k]])\n",
    "        if y_prob_var[k] < 0.5:\n",
    "            break\n",
    "    return log, y_prob_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None, None, 0.9780473453499616],\n",
       " [27, 'shit', 0.6740743903054798],\n",
       " [22, 'me', 0.5742807959783442],\n",
       " [14, 'give a', 0.4841897354143122]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log, y_prob_base = explain_prediction_cf(comment, tokens, pipe)\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's format this for ease of consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf(comment, tokens, pipe):\n",
    "    log, y_prob_base = explain_prediction_cf(comment, tokens, pipe)\n",
    "    html = '<pre><h2>Explanation</h2>\\n'\n",
    "    html += 'Removing {'\n",
    "    for row in log[1:]:\n",
    "        html += '\"%s\", ' % row[1]\n",
    "    html = html[:-2]\n",
    "    html += '} from the text changes the toxicity score from %0.1f%% to %0.1f%%.' % (100*log[0][2], 100*log[-1][2])\n",
    "    # Now let's add the original comment with highlighted text\n",
    "    for row in log[1:]:\n",
    "        token = row[1]\n",
    "        comment = re.sub(r'\\b%s\\b' % token, '<span style=\"background-color: rgba(255, 0, 0, 0.2)\">%s</span>' % token, comment, flags=re.IGNORECASE)  \n",
    "    html += '<h2>Original</h2>\\n%s</pre>' % comment\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><h2>Explanation</h2>\n",
       "Removing {\"shit\", \"me\", \"give a\"} from the text changes the toxicity score from 97.8% to 48.4%.<h2>Original</h2>\n",
       "\"\n",
       "::Block <span style=\"background-color: rgba(255, 0, 0, 0.2)\">me</span>. I really don't <span style=\"background-color: rgba(255, 0, 0, 0.2)\">give a</span> <span style=\"background-color: rgba(255, 0, 0, 0.2)\">shit</span>! If a source doesn't work for someone, it gets removed. K?    \"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(get_cf(comment, tokens, pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 8 August 2009 (UTC)\n",
      "\n",
      "\n",
      "I just saw Xeno's edit comment - A Phone Call????? That's a reliable source that verified it for you???? You're a lousy editor, biased, obstructionist and fixed on defending your article. Fact is the claim was unsupported and unverified and should not be in here until such time as a Reliable Source was produced. You've been completely unable and incapable of providing a source yet more than happy to keep your edit by any means possible. Absolute garbage - and I detest your unsupported allegations that I'm a fucking teabagger, Republican or one-subject editor -ESPECIALLY since I provided supporting links to my NPOV editing. This is how you support an edit: You give it a proper name: Suncoast Regional Emmy Award /You give it a year: 2000. /You give it a title: A Grave Injustice /You give it a channel: WDSU, New Orleans - AND YOU PROVIDE A RELIABLE SOURCE: And you do it without bias according to supporting references. Your a biased hack, your attacks, ignorance, incompetence and obstructionism did nothing to better this article, they only serve to drive those you bully away from the project. Don't be a Dick. Oh, and the last 1/2 of the article is garbage fluff that serves no purpose other than to keep the guards and gatekeepers employed. But then anyone who takes issue with your precious must be a Republican Secret Agent bent on who knows what fantasy exists in your mind. And yes, your dickishness here does piss off us neutral editors. Like myself, editing NPOV since '01.  04:38\n"
     ]
    }
   ],
   "source": [
    "comment_2 = df_test.loc[17621, 'comment']\n",
    "print(comment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><h2>Explanation</h2>\n",
       "Removing {\"you\", \"garbage\", \"your\", \"piss\", \"a dick\", \"re a\", \"off\", \"oh\"} from the text changes the toxicity score from 100.0% to 36.2%.<h2>Original</h2>\n",
       ", 8 August 2009 (UTC)\n",
       "\n",
       "\n",
       "I just saw Xeno's edit comment - A Phone Call????? That's a reliable source that verified it for <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>???? <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>'<span style=\"background-color: rgba(255, 0, 0, 0.2)\">re a</span> lousy editor, biased, obstructionist and fixed on defending <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> article. Fact is the claim was unsupported and unverified and should not be in here until such time as a Reliable Source was produced. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>'ve been completely unable and incapable of providing a source yet more than happy to keep <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> edit by any means possible. Absolute <span style=\"background-color: rgba(255, 0, 0, 0.2)\">garbage</span> - and I detest <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> unsupported allegations that I'm a fucking teabagger, Republican or one-subject editor -ESPECIALLY since I provided supporting links to my NPOV editing. This is how <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> support an edit: <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a proper name: Suncoast Regional Emmy Award /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a year: 2000. /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a title: A Grave Injustice /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a channel: WDSU, New Orleans - AND <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> PROVIDE A RELIABLE SOURCE: And <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> do it without bias according to supporting references. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> a biased hack, <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> attacks, ignorance, incompetence and obstructionism did nothing to better this article, they only serve to drive those <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> bully away from the project. Don't be <span style=\"background-color: rgba(255, 0, 0, 0.2)\">a dick</span>. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">oh</span>, and the last 1/2 of the article is <span style=\"background-color: rgba(255, 0, 0, 0.2)\">garbage</span> fluff that serves no purpose other than to keep the guards and gatekeepers employed. But then anyone who takes issue with <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> precious must be a Republican Secret Agent bent on who knows what fantasy exists in <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> mind. And yes, <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> dickishness here does <span style=\"background-color: rgba(255, 0, 0, 0.2)\">piss</span> <span style=\"background-color: rgba(255, 0, 0, 0.2)\">off</span> us neutral editors. Like myself, editing NPOV since '01.  04:38</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(get_cf(comment_2, tokens, pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Surrogate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local surrogate models are interpretable models (e.g., Logistic Regression, Decision Tree, etc.) that are used to explain individual predictions of black box machine learning models. The steps for computing a local surrogate model are as follows:\n",
    "\n",
    "1. Generate variants by randomly masking (blanking) features found in the base instance.\n",
    "2. Compute distance between base instance and each variant.\n",
    "3. Compute scores for each variant.\n",
    "4. Train an interpretable model using the inverse distance as the sample weight.\n",
    "5. Interpret the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by vectorizing the comment (base instance) and randomly masking features from it to create variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13683,  18982,  19217,  88832,  88962, 152681, 152682, 153245,\n",
       "       153256, 186689, 189069, 201036, 201126, 201907, 201909, 229569,\n",
       "       230727, 232375, 232385, 254303, 255014, 262939, 290807, 291167,\n",
       "       388853, 389014, 396308, 424082, 424153, 435431, 435600, 437394,\n",
       "       437507, 454940, 455496, 456398, 547563, 547652])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pipe.named_steps['vect'].transform([comment]).toarray()\n",
    "idx_nonzero = np.nonzero(X.flatten())[0]\n",
    "idx_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([0,1], size=(100, idx_nonzero.shape[0]), p=[0.2,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = np.repeat(X, repeats=100, axis=0)\n",
    "X_var[:, idx_nonzero] = mask*X_var[:, idx_nonzero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92932038, 0.94146887, 0.91701095, 0.8660254 , 0.83937206])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = cosine_similarity(X_var, X).flatten()\n",
    "sim[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97019489, 0.95105696, 0.96889938, 0.97989539, 0.92555573,\n",
       "       0.43630836, 0.96978832, 0.78926859, 0.98386264, 0.64729942,\n",
       "       0.96535687, 0.94732183, 0.69693903, 0.98377088, 0.97858002,\n",
       "       0.97050126, 0.97418296, 0.96731702, 0.95671203, 0.55242902,\n",
       "       0.74329257, 0.9819456 , 0.98746605, 0.97406047, 0.97280599,\n",
       "       0.98508819, 0.66433111, 0.97492093, 0.97106533, 0.94439904,\n",
       "       0.95820659, 0.62470695, 0.9477999 , 0.98789114, 0.97636115,\n",
       "       0.54214197, 0.87357502, 0.98507409, 0.6270072 , 0.97886626,\n",
       "       0.96839777, 0.97371749, 0.96132969, 0.95947663, 0.67619483,\n",
       "       0.97377879, 0.30413632, 0.98656777, 0.98299359, 0.9687295 ,\n",
       "       0.56434967, 0.95452144, 0.97958165, 0.46180748, 0.96399527,\n",
       "       0.96714973, 0.97945948, 0.93634001, 0.64978137, 0.96627083,\n",
       "       0.95530905, 0.59228667, 0.97130483, 0.97422419, 0.93618556,\n",
       "       0.97834238, 0.98371783, 0.96901908, 0.49515367, 0.95564086,\n",
       "       0.98426733, 0.94911348, 0.98442473, 0.98931216, 0.97072841,\n",
       "       0.66505301, 0.78878795, 0.98233255, 0.76594203, 0.55685288,\n",
       "       0.94067736, 0.97157301, 0.94855928, 0.96107018, 0.97912177,\n",
       "       0.9649201 , 0.97395909, 0.96712448, 0.9692556 , 0.96206679,\n",
       "       0.97227083, 0.9638789 , 0.9701754 , 0.97924323, 0.57539079,\n",
       "       0.96388838, 0.9724422 , 0.98125368, 0.55005475, 0.96836067])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(X_var)[:,1]\n",
    "y_prob_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=101, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Ridge(random_state=seed)\n",
    "clf.fit(X_var, y_prob_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547563</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.036465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230727</th>\n",
       "      <td>i really</td>\n",
       "      <td>-0.030787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291167</th>\n",
       "      <td>me i</td>\n",
       "      <td>-0.023506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435431</th>\n",
       "      <td>someone</td>\n",
       "      <td>-0.023292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232385</th>\n",
       "      <td>if a</td>\n",
       "      <td>-0.022960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token      coef\n",
       "547563      work -0.036465\n",
       "230727  i really -0.030787\n",
       "291167      me i -0.023506\n",
       "435431   someone -0.023292\n",
       "232385      if a -0.022960"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local = pd.DataFrame({'token':tokens, 'coef':clf.coef_.flatten()})\n",
    "df_local.sort_values('coef', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424082</th>\n",
       "      <td>shit</td>\n",
       "      <td>0.332040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88832</th>\n",
       "      <td>block</td>\n",
       "      <td>0.041888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290807</th>\n",
       "      <td>me</td>\n",
       "      <td>0.034108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201909</th>\n",
       "      <td>give a</td>\n",
       "      <td>0.033178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455496</th>\n",
       "      <td>t give</td>\n",
       "      <td>0.022423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token      coef\n",
       "424082    shit  0.332040\n",
       "88832    block  0.041888\n",
       "290807      me  0.034108\n",
       "201909  give a  0.033178\n",
       "455496  t give  0.022423"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.sort_values('coef', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 38)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,38) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-6e1c92e6627e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_variants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_nonzero\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,38) (2,) "
     ]
    }
   ],
   "source": [
    "mask\n",
    "X_variants[:, idx_nonzero]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop one token at a time and create variations on the original comment. We'll keep the original comment as the first item for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wikipedia is total crap!',\n",
       " 'Wikipedia is total !',\n",
       " 'Wikipedia  total crap!',\n",
       " 'Wikipedia is  crap!',\n",
       " 'Wikipedia is total crap!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = [comment]\n",
    "for token in sorted(set(tokens)): # The set is very important!\n",
    "    variants.append(re.sub(token, '', comment))\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crap', 'is', 'total', 'wikipedia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new scores. Let's only look at the probability related to the positive case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96419754, 0.59595006, 0.95051515, 0.93706812, 0.96419754])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = pipe.predict_proba(variants)[:,1]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the difference from the base score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36824748, 0.01368239, 0.02712943, 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_diffs = y_probs[0] - y_probs[1:]\n",
    "y_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assign these score differences as background spans in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crap': 0.36824748498106574,\n",
       " 'is': 0.013682391040973019,\n",
       " 'total': 0.02712942587769296,\n",
       " 'wikipedia': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict = {k:v for k,v in zip(list(sorted(set(tokens))), y_diffs)}\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Wikipedia <span style=\"background-color: rgba(255, 0, 0, 0.01)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">total</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">crap</span>!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = '<pre>' + comment + '</pre>'\n",
    "for k,v in weight_dict.items():\n",
    "    span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)\n",
    "    output = re.sub(k, span_string, output)\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now let's try and functionalize that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_toxic(text, pipe, norm=False):\n",
    "    # Get tokens\n",
    "    tokens = tokenizer(text)\n",
    "    # Create variants\n",
    "    variants = [text]\n",
    "    for token in sorted(set(tokens)):\n",
    "        variants.append(re.sub(token, '', text))\n",
    "    # Score variants\n",
    "    y_probs = pipe.predict_proba(variants)[:,1]\n",
    "    # Compute differences from base score \n",
    "    y_diffs = y_probs[0] - y_probs[1:]\n",
    "    # Normalize\n",
    "    if norm:\n",
    "        y_diffs /= np.linalg.norm(y_diffs, ord=1)\n",
    "    # Assign weights to tokens\n",
    "    weight_dict = {k:v for k,v in zip(list(sorted(set(tokens))), y_diffs)}\n",
    "    # Generate output\n",
    "    output = '<pre>' + text + '</pre>'\n",
    "    for k,v in weight_dict.items():\n",
    "        span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)\n",
    "        output = re.sub(r'\\b%s\\b' % k, span_string, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93358762 0.06641238]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Thank <span style=\"background-color: rgba(255, 0, 0, -0.06)\">you</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">for</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">suggestion</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('Thank you for the suggestion', pipe)\n",
    "print(pipe.predict_proba(['Thank you for the suggestion']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77770784 0.22229216]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>I <span style=\"background-color: rgba(255, 0, 0, -0.08)\">hope</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">you</span> <span style=\"background-color: rgba(255, 0, 0, -0.14)\">have</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">bad</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">day</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('I hope you have a bad day', pipe)\n",
    "print(pipe.predict_proba(['I hope you have a bad day']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06290301 0.93709699]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>This <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.16)\">worst</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">edit</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">ever</span>. Go <span style=\"background-color: rgba(255, 0, 0, 0.04)\">jump</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">off</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">bridge</span>.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('This is the worst edit ever. Go jump off a bridge.', pipe)\n",
    "print(pipe.predict_proba(['This is the worst edit ever. Go jump off a bridge.']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on some random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_comments = df[df['y']==0].sample(10, random_state=seed)['comment']\n",
    "y_prob_normal = pipe.predict_proba(normal_comments)\n",
    "normal_examples = [highlight_toxic(comment, pipe) for comment in normal_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96518533 0.03481467]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "*Pursuant <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> Wikipedia:Verifiability, \"\"The <span style=\"background-color: rgba(255, 0, 0, 0.01)\">threshold</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">for</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">inclusion</span> <span style=\"background-color: rgba(255, 0, 0, -0.11)\">in</span> Wikipedia <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">verifiability</span>\"\". The <span style=\"background-color: rgba(255, 0, 0, 0.01)\">only</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">reason</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">content</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">should</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">removed</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">from</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">an</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">if</span> <span style=\"background-color: rgba(255, 0, 0, -0.12)\">it</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">cannot</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">verified</span>.  <span style=\"background-color: rgba(255, 0, 0, 0.01)\">repeated</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">removal</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">subject</span>'<span style=\"background-color: rgba(255, 0, 0, -0.04)\">s</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">must</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">stop</span>. He <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">deliberately</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">trying</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">compromise</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">integrity</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> Wikipedia <span style=\"background-color: rgba(255, 0, 0, -0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">ignoring</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">consensus</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> AfD <span style=\"background-color: rgba(255, 0, 0, -0.00)\">discussion</span>, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">continuing</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.04)\">edit</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">war</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">against</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">thi</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">that</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">he</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">took</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">position</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">delete</span>. The AfD <span style=\"background-color: rgba(255, 0, 0, -0.02)\">consensus</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">was</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">delete</span>. The <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">are</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">verifiable</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">they</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">should</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">removed</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">from</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span>.  '<span style=\"background-color: rgba(255, 0, 0, -0.04)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">repeated</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">removal</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">such</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">constitutes</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">vandalism</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">pursuant</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> Wikipedia:Vandalism, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">he</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">has</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">been</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">warned</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">stop</span>.   \"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "print(y_prob_normal[i])\n",
    "HTML(normal_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = df[df['y']==1].sample(10, random_state=seed)['comment']\n",
    "y_prob_toxic = pipe.predict_proba(toxic_comments)\n",
    "toxic_examples = [highlight_toxic(comment, pipe) for comment in toxic_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40919978 0.59080022]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "\n",
       "I <span style=\"background-color: rgba(255, 0, 0, 0.03)\">suggest</span> <span style=\"background-color: rgba(255, 0, 0, 0.07)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">get</span> <span style=\"background-color: rgba(255, 0, 0, 0.08)\">some</span> <span style=\"background-color: rgba(255, 0, 0, 0.24)\">mental</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">help</span>.  </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37620651 0.62379349]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "== Hubris ==\n",
       "\n",
       "Your <span style=\"background-color: rgba(255, 0, 0, 0.02)\">unconscionable</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">hubris</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">will</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">your</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">downfall</span>. With <span style=\"background-color: rgba(255, 0, 0, -0.07)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">simple</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">sword</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">truth</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">will</span> I <span style=\"background-color: rgba(255, 0, 0, 0.01)\">vanquish</span> <span style=\"background-color: rgba(255, 0, 0, 0.20)\">ye</span>. Indeed, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">woe</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">unto</span> <span style=\"background-color: rgba(255, 0, 0, 0.20)\">ye</span>, <span style=\"background-color: rgba(255, 0, 0, -0.04)\">for</span> I <span style=\"background-color: rgba(255, 0, 0, 0.01)\">wax</span> <span style=\"background-color: rgba(255, 0, 0, 0.30)\">terrible</span>, <span style=\"background-color: rgba(255, 0, 0, 0.02)\">wielding</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">blade</span>, <span style=\"background-color: rgba(255, 0, 0, 0.02)\">ready</span> <span style=\"background-color: rgba(255, 0, 0, -0.08)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">smite</span>.   </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24845623 0.75154377]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "==NPOV==\n",
       "<span style=\"background-color: rgba(255, 0, 0, 0.06)\">damnit</span>, <span style=\"background-color: rgba(255, 0, 0, -0.01)\">liberals</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">blogger</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">are</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">going</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">try</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">spin</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.52)\">hell</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">out</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">look</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">at</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">version</span> <span style=\"background-color: rgba(255, 0, 0, -0.21)\">it</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">was</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">protected</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">on</span>! Why <span style=\"background-color: rgba(255, 0, 0, 0.24)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.04)\">something</span> <span style=\"background-color: rgba(255, 0, 0, -0.13)\">as</span> <span style=\"background-color: rgba(255, 0, 0, -0.09)\">minor</span> <span style=\"background-color: rgba(255, 0, 0, -0.13)\">as</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">hunting</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">accident</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">even</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">listed</span> <span style=\"background-color: rgba(255, 0, 0, 0.16)\">in</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">article</span>! It <span style=\"background-color: rgba(255, 0, 0, -0.06)\">reads</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">like</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">blog</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">from</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.27)\">freaking</span> Daily Kos, <span style=\"background-color: rgba(255, 0, 0, -0.07)\">please</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">clean</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">up</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">conform</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> Neutral POV, <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.06)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">exploit</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.09)\">minor</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">accident</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">like</span> <span style=\"background-color: rgba(255, 0, 0, -0.21)\">it</span>'<span style=\"background-color: rgba(255, 0, 0, -0.15)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">big</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">deal</span>! </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.18633803e-06 9.99996814e-01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "== Gregalton: Douchemaster Supreme ==\n",
       "\n",
       "I'<span style=\"background-color: rgba(255, 0, 0, 0.00)\">m</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">an</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">editor</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">so</span> I <span style=\"background-color: rgba(255, 0, 0, -0.00)\">really</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">don</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">t</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">have</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">problem</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">calling</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>. The <span style=\"background-color: rgba(255, 0, 0, 0.00)\">fact</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">that</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">considers</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">anyone</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">who</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">criticizes</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">practice</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">of</span> FRB <span style=\"background-color: rgba(255, 0, 0, 0.00)\">as</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">non</span>-<span style=\"background-color: rgba(255, 0, 0, -0.00)\">mainstream</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">raised</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">flag</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">in</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">my</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">mind</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">that</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">is</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">made</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">me</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">check</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">discussion</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">page</span>. You'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">ve</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">done</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">more</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">bias</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">than</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">these</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">supposed</span> \"\"<span style=\"background-color: rgba(255, 0, 0, 0.00)\">conspiracy</span>\"\" <span style=\"background-color: rgba(255, 0, 0, -0.00)\">people</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">probably</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">did</span>. At <span style=\"background-color: rgba(255, 0, 0, 0.00)\">any</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">rate</span>, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">fuck</span> Wikipedia, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">fuck</span> Gregalton; I <span style=\"background-color: rgba(255, 0, 0, -0.00)\">wait</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">for</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">day</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">when</span> Knol (<span style=\"background-color: rgba(255, 0, 0, 0.00)\">google</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">wikipedia</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">written</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">experts</span>: <span style=\"background-color: rgba(255, 0, 0, 0.00)\">reality</span>, <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">wikiality</span>) <span style=\"background-color: rgba(255, 0, 0, 0.00)\">has</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">good</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">under</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">same</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">title</span> (<span style=\"background-color: rgba(255, 0, 0, -0.00)\">and</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">it</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">s</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">written</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">one</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">these</span> \"\"<span style=\"background-color: rgba(255, 0, 0, -0.00)\">non</span>-<span style=\"background-color: rgba(255, 0, 0, -0.00)\">mainstream</span>\"\" <span style=\"background-color: rgba(255, 0, 0, -0.00)\">economists</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">talks</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">about</span>).\n",
       "\n",
       "You'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">re</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">gregalton</span>.  A <span style=\"background-color: rgba(255, 0, 0, 0.00)\">big</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">fat</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">fractional</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">reserve</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">banking</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">loving</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>.\"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...it seems like dropping out one token at a time isn't going to cut it. Even though the model is scoring this comment as toxic, it is having some issues highlighting specific segments. Let's dive into the model and drive highlighting by the exact contribution to each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = toxic_comments.values[8]\n",
    "features = pipe.named_steps['vect'].get_feature_names() # Don't cast this to a numpy array...\n",
    "counts = pipe.named_steps['vect'].transform([comment]).toarray().flatten()\n",
    "w = pipe.named_steps['clf'].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.9506251995001473,\n",
       " 'about': -0.2573779969605216,\n",
       " 'an': 0.24775747406102963,\n",
       " 'and': -0.26113798744752736,\n",
       " 'any': -0.04195150960840179,\n",
       " 'anyone': -0.17851617027838612,\n",
       " 'article': -0.917904310846447,\n",
       " 'as': -0.1915447073542239,\n",
       " 'at': -0.1695905146795088,\n",
       " 'banking': -0.21517154754479062,\n",
       " 'bias': 0.14695020051432892,\n",
       " 'big': 0.4201936147568579,\n",
       " 'by': -0.007789988269459465,\n",
       " 'calling': -0.004525334154367213,\n",
       " 'check': -0.32613314230385276,\n",
       " 'considers': 0.03558991071102402,\n",
       " 'conspiracy': 0.08777763038538694,\n",
       " 'criticizes': -0.022762161378118775,\n",
       " 'day': -0.07177890620233918,\n",
       " 'did': -0.23221968775288868,\n",
       " 'discussion': -0.15508429059649287,\n",
       " 'don': -0.028806586242888867,\n",
       " 'done': -0.09142575896360813,\n",
       " 'douchebag': 3.0288359785357937,\n",
       " 'economists': -0.02508670957939663,\n",
       " 'editor': -0.10446221268238955,\n",
       " 'experts': 0.04890261771595807,\n",
       " 'fact': -0.03430937874263487,\n",
       " 'fat': 1.1855633862722827,\n",
       " 'flag': 0.16822040909077168,\n",
       " 'for': 0.02230599771168577,\n",
       " 'fractional': -0.04673646030556804,\n",
       " 'frb': 0.0077160082442503065,\n",
       " 'fuck': 8.032156164072816,\n",
       " 'good': -0.23252073026801426,\n",
       " 'google': 0.317427293756958,\n",
       " 'gregalton': -0.5946911110565586,\n",
       " 'has': -0.05859799166191128,\n",
       " 'have': -0.23444319524254675,\n",
       " 'i': -0.31713152916243365,\n",
       " 'in': -0.22041271711896077,\n",
       " 'is': 0.036294802033222016,\n",
       " 'it': -0.06461719137125699,\n",
       " 'knol': -0.1069241626165296,\n",
       " 'loving': -0.04243954840495195,\n",
       " 'm': -0.012797724100646436,\n",
       " 'made': -0.18525889100486467,\n",
       " 'mainstream': -0.5541211709739405,\n",
       " 'me': 0.4273328271330389,\n",
       " 'mind': 0.11550303277330212,\n",
       " 'more': 0.04918948504446273,\n",
       " 'my': 0.31918858540680567,\n",
       " 'non': -0.2655386190167365,\n",
       " 'not': 0.2772023777712694,\n",
       " 'of': 0.06491508666760028,\n",
       " 'one': -0.1956460824759826,\n",
       " 'page': 0.13772629372601464,\n",
       " 'people': -0.09850090347813027,\n",
       " 'practice': -0.16442336899698343,\n",
       " 'probably': -0.09409650854914578,\n",
       " 'problem': 0.10170696156347236,\n",
       " 'raised': -0.08180406543765435,\n",
       " 'rate': -0.39668555095952474,\n",
       " 're': -0.023295421949223155,\n",
       " 'reality': 0.12423672047951936,\n",
       " 'really': 0.09238072426616901,\n",
       " 'reserve': -0.1336393505439358,\n",
       " 's': -0.3976797308964246,\n",
       " 'same': -0.05745187865447148,\n",
       " 'so': -0.010975581138590238,\n",
       " 'supposed': -0.22478279814643087,\n",
       " 'supreme': -0.23248713617682784,\n",
       " 't': -0.012280844708192237,\n",
       " 'talks': 0.09774048149624498,\n",
       " 'than': 0.06155289312738878,\n",
       " 'that': -0.19885068244223306,\n",
       " 'the': -1.7485590207925203,\n",
       " 'these': 0.3663171714130783,\n",
       " 'title': -0.27860169622741066,\n",
       " 'to': -0.15440880084723904,\n",
       " 'under': 0.05427985192116989,\n",
       " 've': -0.20759966159635773,\n",
       " 'wait': -0.011993668358385553,\n",
       " 'when': -0.09468607998783987,\n",
       " 'who': 0.2475689408855331,\n",
       " 'wikiality': 0.39443945983711726,\n",
       " 'wikipedia': 1.182131736417235,\n",
       " 'written': 0.16752572606676347,\n",
       " 'you': 1.5747210968102785}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(counts > 0)[0]\n",
    "weight_dict = {}\n",
    "for i in idx:\n",
    "    if len(features[i].split(' ')) == 1: # Only keep unigrams\n",
    "        weight_dict[features[i]] = w[i]*counts[i]\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '<pre>' + comment + '</pre>'\n",
    "for k,v in weight_dict.items():\n",
    "    if v < 0:\n",
    "        pass\n",
    "    else:\n",
    "        span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)        \n",
    "        output = re.sub(r'\\b%s\\b' % k, span_string, output, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "== Gregalton: Douchemaster Supreme ==\n",
       "\n",
       "I'm <span style=\"background-color: rgba(255, 0, 0, 0.28)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.25)\">an</span> editor, so I <span style=\"background-color: rgba(255, 0, 0, 0.09)\">really</span> don't have <span style=\"background-color: rgba(255, 0, 0, 0.95)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">problem</span> calling <span style=\"background-color: rgba(255, 0, 0, 1.57)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.95)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 3.03)\">douchebag</span>. The fact that the article <span style=\"background-color: rgba(255, 0, 0, 0.04)\">considers</span> anyone <span style=\"background-color: rgba(255, 0, 0, 0.25)\">who</span> criticizes the practice <span style=\"background-color: rgba(255, 0, 0, 0.06)\">of</span> FRB as non-mainstream raised the <span style=\"background-color: rgba(255, 0, 0, 0.17)\">flag</span> in <span style=\"background-color: rgba(255, 0, 0, 0.32)\">my</span> <span style=\"background-color: rgba(255, 0, 0, 0.12)\">mind</span>, that <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span>, made <span style=\"background-color: rgba(255, 0, 0, 0.43)\">me</span> check the discussion <span style=\"background-color: rgba(255, 0, 0, 0.14)\">page</span>. You've done <span style=\"background-color: rgba(255, 0, 0, 0.05)\">more</span> to <span style=\"background-color: rgba(255, 0, 0, 0.15)\">bias</span> the article <span style=\"background-color: rgba(255, 0, 0, 0.06)\">than</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">these</span> supposed \"\"<span style=\"background-color: rgba(255, 0, 0, 0.09)\">conspiracy</span>\"\" people probably did. At any rate, <span style=\"background-color: rgba(255, 0, 0, 8.03)\">fuck</span> Wikipedia, and <span style=\"background-color: rgba(255, 0, 0, 8.03)\">fuck</span> Gregalton; I wait <span style=\"background-color: rgba(255, 0, 0, 0.02)\">for</span> the day when Knol (<span style=\"background-color: rgba(255, 0, 0, 0.32)\">google</span>'s <span style=\"background-color: rgba(255, 0, 0, 1.18)\">wikipedia</span>, <span style=\"background-color: rgba(255, 0, 0, 0.17)\">written</span> by <span style=\"background-color: rgba(255, 0, 0, 0.05)\">experts</span>: <span style=\"background-color: rgba(255, 0, 0, 0.12)\">reality</span>, <span style=\"background-color: rgba(255, 0, 0, 0.28)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.39)\">wikiality</span>) has a good article <span style=\"background-color: rgba(255, 0, 0, 0.05)\">under</span> the same title (and it's <span style=\"background-color: rgba(255, 0, 0, 0.17)\">written</span> by one <span style=\"background-color: rgba(255, 0, 0, 0.06)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">these</span> \"\"non-mainstream\"\" economists the article <span style=\"background-color: rgba(255, 0, 0, 0.10)\">talks</span> about).\n",
       "\n",
       "You're a <span style=\"background-color: rgba(255, 0, 0, 3.03)\">douchebag</span>, gregalton.  A <span style=\"background-color: rgba(255, 0, 0, 0.42)\">big</span> <span style=\"background-color: rgba(255, 0, 0, 1.19)\">fat</span> fractional reserve banking loving douchebag.\"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the functional form of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_toxic(comment, pipe, features, w):\n",
    "    counts = pipe.named_steps['vect'].transform([comment]).toarray().flatten()\n",
    "    # Build weight dictionary (unigram only)\n",
    "    idx = np.where(counts > 0)[0]\n",
    "    weight_dict = {}\n",
    "    for i in idx:\n",
    "        if len(features[i].split(' ')) == 1: # Only keep unigrams\n",
    "            weight_dict[features[i]] = w[i]*counts[i]\n",
    "    # Scale to max value\n",
    "    \n",
    "    # Insert spans\n",
    "    output = '<pre>' + comment + '</pre>'\n",
    "    for k,v in weight_dict.items():\n",
    "        if v < 0:\n",
    "            pass\n",
    "        else:\n",
    "            # Some regex magic for keeping the original case\n",
    "            span_string = r'<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">\\1</span>' % v\n",
    "            output = re.sub(r'(?i)(\\b%s\\b)' % k, span_string, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pipe.named_steps['vect'].get_feature_names()\n",
    "w = pipe.named_steps['clf'].coef_.flatten()\n",
    "toxic_examples = [highlight_toxic(comment, pipe, features, w) for comment in toxic_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "== <span style=\"background-color: rgba(255, 0, 0, 0.44)\">BONGWARRIOR</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">IS</span> <span style=\"background-color: rgba(255, 0, 0, 0.19)\">A</span> <span style=\"background-color: rgba(255, 0, 0, 0.11)\">GIGANTIC</span> <span style=\"background-color: rgba(255, 0, 0, 2.38)\">ASSHOLE</span>.  ==\n",
       "\n",
       "I WILL <span style=\"background-color: rgba(255, 0, 0, 0.03)\">DIG</span> <span style=\"background-color: rgba(255, 0, 0, 0.28)\">UP</span> <span style=\"background-color: rgba(255, 0, 0, 0.33)\">YOUR</span> GRANDMOTHER AND <span style=\"background-color: rgba(255, 0, 0, 3.07)\">SHIT</span> ON <span style=\"background-color: rgba(255, 0, 0, 0.26)\">HER</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">DENTURES</span>.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(toxic_examples[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "==<span style=\"background-color: rgba(255, 0, 0, 0.30)\">NPOV</span>==\n",
       "<span style=\"background-color: rgba(255, 0, 0, 0.32)\">damnit</span>, <span style=\"background-color: rgba(255, 0, 0, 0.00)\">liberals</span> and <span style=\"background-color: rgba(255, 0, 0, 0.04)\">blogger</span> <span style=\"background-color: rgba(255, 0, 0, 0.26)\">are</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">going</span> to try and <span style=\"background-color: rgba(255, 0, 0, 0.13)\">spin</span> the <span style=\"background-color: rgba(255, 0, 0, 1.58)\">hell</span> <span style=\"background-color: rgba(255, 0, 0, 0.06)\">out</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span>, look at the version it was <span style=\"background-color: rgba(255, 0, 0, 0.12)\">protected</span> on! <span style=\"background-color: rgba(255, 0, 0, 0.06)\">Why</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span> something as minor as <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.21)\">hunting</span> accident even listed in <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span> article! It reads <span style=\"background-color: rgba(255, 0, 0, 0.35)\">like</span> <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.27)\">blog</span> from the <span style=\"background-color: rgba(255, 0, 0, 0.79)\">freaking</span> Daily <span style=\"background-color: rgba(255, 0, 0, 0.00)\">Kos</span>, please <span style=\"background-color: rgba(255, 0, 0, 0.02)\">clean</span> <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span> <span style=\"background-color: rgba(255, 0, 0, 0.28)\">up</span> to <span style=\"background-color: rgba(255, 0, 0, 0.07)\">conform</span> to Neutral <span style=\"background-color: rgba(255, 0, 0, 0.02)\">POV</span>, and <span style=\"background-color: rgba(255, 0, 0, 0.14)\">not</span> exploit <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> minor accident <span style=\"background-color: rgba(255, 0, 0, 0.35)\">like</span> it's <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.42)\">big</span> deal! </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(toxic_examples[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
