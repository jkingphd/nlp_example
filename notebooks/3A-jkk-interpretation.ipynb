{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          0  article  random   test  0.0  1.0  0.1  0  \n",
       "3          1  article  random  train  0.0  2.0  0.6  0  \n",
       "4          1  article  random   test -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sql.connect('../data/toxic.db') as conn:\n",
    "    df = pd.read_sql_query('''select * from toxic''', conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into two seperate dataframes: df_train and df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>\"\\n\\n\\nI fixed the link; I also removed \"\"home...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>\"If they are \"\"indisputable\"\" then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "3  37330.0  \"\\n\\n\\nI fixed the link; I also removed \"\"home...  2002   \n",
       "4  37346.0  \"If they are \"\"indisputable\"\" then why does th...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          1  article  random  train  0.0  2.0  0.6  0  \n",
       "3          1  article  random  train -1.0  1.0  0.1  0  \n",
       "4          1  article  random  train -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['split'] == 'train'].copy().reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['split'] == 'test'].copy().reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab our \"best\" model from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return re.findall(r'[a-z0-9]+', text.lower())\n",
    "\n",
    "gs = load('../results/gs_cv_sgd.joblib')\n",
    "pipe = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make things easier, let's compute probabilities for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y    y_prob  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  0.244198  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  0.172840  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  0.003700  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  0.008976  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  0.007818  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['y_prob'] = pipe.predict_proba(df_test['comment'])[:,1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is a linear model, let's start by looking at the tokens that are most important for predicting each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.485310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0</td>\n",
       "      <td>0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 00</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 005</td>\n",
       "      <td>-0.007528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 01</td>\n",
       "      <td>-0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token    weight\n",
       "0      0 -0.485310\n",
       "1    0 0  0.039417\n",
       "2   0 00 -0.000088\n",
       "3  0 005 -0.007528\n",
       "4   0 01 -0.002821"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pipe.named_steps['vect'].get_feature_names() # Note, NOT the same as vocabulary_\n",
    "weights = pipe.named_steps['clf'].coef_[0]\n",
    "df_model = pd.DataFrame({'token':tokens, 'weight':weights})\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463216</th>\n",
       "      <td>thanks</td>\n",
       "      <td>-1.575386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127997</th>\n",
       "      <td>cool you</td>\n",
       "      <td>-1.079754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463188</th>\n",
       "      <td>thank you</td>\n",
       "      <td>-1.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220356</th>\n",
       "      <td>hey hey</td>\n",
       "      <td>-0.978156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58988</th>\n",
       "      <td>are cool</td>\n",
       "      <td>-0.958368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463160</th>\n",
       "      <td>thank</td>\n",
       "      <td>-0.863174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189578</th>\n",
       "      <td>for your</td>\n",
       "      <td>-0.836592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130100</th>\n",
       "      <td>could you</td>\n",
       "      <td>-0.775153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393418</th>\n",
       "      <td>regards</td>\n",
       "      <td>-0.771566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228178</th>\n",
       "      <td>http en</td>\n",
       "      <td>-0.759324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token    weight\n",
       "463216     thanks -1.575386\n",
       "127997   cool you -1.079754\n",
       "463188  thank you -1.015618\n",
       "220356    hey hey -0.978156\n",
       "58988    are cool -0.958368\n",
       "463160      thank -0.863174\n",
       "189578   for your -0.836592\n",
       "130100  could you -0.775153\n",
       "393418    regards -0.771566\n",
       "228178    http en -0.759324"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88865</th>\n",
       "      <td>block block</td>\n",
       "      <td>12.789651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315629</th>\n",
       "      <td>nipple nipple</td>\n",
       "      <td>11.052719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315628</th>\n",
       "      <td>nipple</td>\n",
       "      <td>10.774228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459260</th>\n",
       "      <td>teabag</td>\n",
       "      <td>9.681863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97787</th>\n",
       "      <td>buttsecks</td>\n",
       "      <td>7.755658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540505</th>\n",
       "      <td>wikipedia hi</td>\n",
       "      <td>5.545768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220792</th>\n",
       "      <td>hi wikipedia</td>\n",
       "      <td>5.399690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195137</th>\n",
       "      <td>fuck</td>\n",
       "      <td>4.016078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109999</th>\n",
       "      <td>chester</td>\n",
       "      <td>3.474630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500501</th>\n",
       "      <td>tommy2010</td>\n",
       "      <td>3.472154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                token     weight\n",
       "88865     block block  12.789651\n",
       "315629  nipple nipple  11.052719\n",
       "315628         nipple  10.774228\n",
       "459260         teabag   9.681863\n",
       "97787       buttsecks   7.755658\n",
       "540505   wikipedia hi   5.545768\n",
       "220792   hi wikipedia   5.399690\n",
       "195137           fuck   4.016078\n",
       "109999        chester   3.474630\n",
       "500501      tommy2010   3.472154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Counterfactual Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a positive example from the test set and find the closest* example from the training set that had the _opposite_ outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31381</th>\n",
       "      <td>684746726.0</td>\n",
       "      <td>\\n\\n== You fascit Nazi! You socialist bastard!...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13718</th>\n",
       "      <td>227050603.0</td>\n",
       "      <td>\"\\n::Block me. I really don't give a shit! If ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12584</th>\n",
       "      <td>207227099.0</td>\n",
       "      <td>\", a Democrat cyber thug, banns me due to diff...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13759</th>\n",
       "      <td>227668942.0</td>\n",
       "      <td>\\n\\n\\nA.K.D.A.H.N why do u keep blockin me for...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>372491007.0</td>\n",
       "      <td>But what do I know, I'm a complete fucking mor...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id                                            comment  year  \\\n",
       "31381  684746726.0  \\n\\n== You fascit Nazi! You socialist bastard!...  2015   \n",
       "13718  227050603.0  \"\\n::Block me. I really don't give a shit! If ...  2008   \n",
       "12584  207227099.0  \", a Democrat cyber thug, banns me due to diff...  2008   \n",
       "13759  227668942.0  \\n\\n\\nA.K.D.A.H.N why do u keep blockin me for...  2008   \n",
       "20486  372491007.0  But what do I know, I'm a complete fucking mor...  2010   \n",
       "\n",
       "       logged_in    ns   sample split  min  max  avg  y    y_prob  \n",
       "31381          1  user  blocked  test -2.0 -1.0 -1.6  1  1.000000  \n",
       "13718          1  user  blocked  test -2.0  0.0 -0.9  1  0.978047  \n",
       "12584          0  user  blocked  test -1.0  1.0 -0.2  1  0.899124  \n",
       "13759          0  user  blocked  test -1.0  1.0 -0.1  1  0.597773  \n",
       "20486          1  user  blocked  test -2.0  0.0 -1.1  1  0.999958  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test_pos = (df_test['y'] == 1) & (df_test['y_prob'] > 0.5)\n",
    "df_test[idx_test_pos].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "comment = df_test.loc[13718]['comment']\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize this comment, vectorize all the training comments, and determine which one is most similar and _not toxic_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_neg = df_train['y'] == 0\n",
    "X_train_neg = pipe.named_steps['vect'].transform(df_train.loc[idx_train_neg, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipe.named_steps['vect'].transform([comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.60\n",
      "Cosine Distance: 0.66\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::::::::::: Okay, found a source, don't know if it's good enough, don't care. It was worth a shot. I apologize for the personal attacks to you, but I'd appreciate it if you wouldn't make sarcastic comments or making fun of what I say. \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "cosine_dist = pairwise_distances(X_train_neg, X, metric='cosine').flatten()\n",
    "print('AVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_dist.argmin()][0])\n",
    "print('Cosine Distance: %0.2f' % cosine_dist.min())\n",
    "print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[cosine_dist.argmin()] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.10\n",
      "Euclidean Distance: 0.10\n",
      "<COMMENT>\n",
      "\n",
      "::::::Rollback still doesn't work. —  / \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "euc_dist = pairwise_distances(X_train_neg, X, metric='euclidean').flatten()\n",
    "print('AVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[euc_dist.argmin()][0])\n",
    "print('Euclidean Distance: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[euc_dist.argmin()][0])\n",
    "print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[euc_dist.argmin()] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the three closest examples with the same label (positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_pos = df_train['y'] == 1\n",
    "X_train_pos = pipe.named_steps['vect'].transform(df_train.loc[idx_train_pos, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.57\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I don't give a flying fuck. block me I Don't care. kiss my goddamn ass. DUSTIN Motherfucking D\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.58\n",
      "<COMMENT>\n",
      "And I don't give a damn.  \n",
      "\n",
      "\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.59\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I AM SO SCARED!!!  PLEASE DON'T BLOCK ME FROM EDITING!  I DON'T KNOW WHAT I'LL DO IF I CAN'T EDIT ARTICLES!  (Actually, this was a sarcastic response to your bullshit warning, you stupid asswipe.  Like I really give a shit.  Block me, you stupid fuck.)\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_dist = pairwise_distances(X_train_pos, X, metric='cosine').flatten()\n",
    "for i in cosine_dist.flatten().argsort()[:3]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[cosine_dist.argmin()][0])\n",
    "    print('Cosine Distance: %0.2f' % cosine_dist[i])\n",
    "#     print(df_train.loc[idx_train_pos, ['avg']].values[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -0.50\n",
      "Euclidean Distance: 6.08\n",
      "<COMMENT>\n",
      "And I don't give a damn.  \n",
      "\n",
      "\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -0.50\n",
      "Euclidean Distance: 6.40\n",
      "<COMMENT>\n",
      "\"\n",
      "::::It doesn't matter. \"\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -0.50\n",
      "Euclidean Distance: 6.48\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I don't care. Asshole! \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "euc_dist = pairwise_distances(X_train_pos, X, metric='euclidean').flatten()\n",
    "for i in euc_dist.flatten().argsort()[:3]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[euc_dist.argmin()][0])\n",
    "    print('Euclidean Distance: %0.2f' % euc_dist[i])\n",
    "#     print(df_train.loc[idx_train_pos, ['avg']].values[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Counterfactual Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of mining our training data for counterfactual examples, let's attempt to _create_ one by dropping word occurances from the original text until the score changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "== Know your place ==\n",
      "\n",
      "If you vandalise any pages again, you will be blocked   \n"
     ]
    }
   ],
   "source": [
    "idx_nonzero = (X.toarray() > 0).astype(int)\n",
    "variants = [comment]\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 560571)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero = np.nonzero(X.toarray().flatten())[0]\n",
    "variants = np.repeat(X.toarray(), len(idx_nonzero) + 1, axis=0) # add one base instance for the original\n",
    "for i, j in enumerate(idx_nonzero):\n",
    "    variants[i+1,j] = 0\n",
    "#     print(np.nonzero(variants[i+1])[0].shape)\n",
    "variants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-096273b1ab2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_prob_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_prob_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'''Removing token \"%s\" changes score from %0.2f to %0.2f'''\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_nonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(variants)[:,1]\n",
    "k = y_prob_var.argmin()\n",
    "print('''Removing token \"%s\" changes score from %0.2f to %0.2f''' % (tokens[idx_nonzero[k]], y_prob_var[0], y_prob_var[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Surrogate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Now let's see if we can use some simple methods to expose decision points. We'll develop a process to tokenize a document and drop out unique tokens. By removing tokens and recomputing the score, we should be able to see how any one token affects the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wikipedia', 'is', 'total', 'crap']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = 'Wikipedia is total crap!'\n",
    "tokens = tokenizer(comment)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop one token at a time and create variations on the original comment. We'll keep the original comment as the first item for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wikipedia is total crap!',\n",
       " 'Wikipedia is total !',\n",
       " 'Wikipedia  total crap!',\n",
       " 'Wikipedia is  crap!',\n",
       " 'Wikipedia is total crap!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = [comment]\n",
    "for token in sorted(set(tokens)): # The set is very important!\n",
    "    variants.append(re.sub(token, '', comment))\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crap', 'is', 'total', 'wikipedia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new scores. Let's only look at the probability related to the positive case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96419754, 0.59595006, 0.95051515, 0.93706812, 0.96419754])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = pipe.predict_proba(variants)[:,1]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the difference from the base score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36824748, 0.01368239, 0.02712943, 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_diffs = y_probs[0] - y_probs[1:]\n",
    "y_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assign these score differences as background spans in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crap': 0.36824748498106574,\n",
       " 'is': 0.013682391040973019,\n",
       " 'total': 0.02712942587769296,\n",
       " 'wikipedia': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict = {k:v for k,v in zip(list(sorted(set(tokens))), y_diffs)}\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Wikipedia <span style=\"background-color: rgba(255, 0, 0, 0.01)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">total</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">crap</span>!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = '<pre>' + comment + '</pre>'\n",
    "for k,v in weight_dict.items():\n",
    "    span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)\n",
    "    output = re.sub(k, span_string, output)\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now let's try and functionalize that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_toxic(text, pipe, norm=False):\n",
    "    # Get tokens\n",
    "    tokens = tokenizer(text)\n",
    "    # Create variants\n",
    "    variants = [text]\n",
    "    for token in sorted(set(tokens)):\n",
    "        variants.append(re.sub(token, '', text))\n",
    "    # Score variants\n",
    "    y_probs = pipe.predict_proba(variants)[:,1]\n",
    "    # Compute differences from base score \n",
    "    y_diffs = y_probs[0] - y_probs[1:]\n",
    "    # Normalize\n",
    "    if norm:\n",
    "        y_diffs /= np.linalg.norm(y_diffs, ord=1)\n",
    "    # Assign weights to tokens\n",
    "    weight_dict = {k:v for k,v in zip(list(sorted(set(tokens))), y_diffs)}\n",
    "    # Generate output\n",
    "    output = '<pre>' + text + '</pre>'\n",
    "    for k,v in weight_dict.items():\n",
    "        span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)\n",
    "        output = re.sub(r'\\b%s\\b' % k, span_string, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93358762 0.06641238]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Thank <span style=\"background-color: rgba(255, 0, 0, -0.06)\">you</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">for</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">suggestion</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('Thank you for the suggestion', pipe)\n",
    "print(pipe.predict_proba(['Thank you for the suggestion']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77770784 0.22229216]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>I <span style=\"background-color: rgba(255, 0, 0, -0.08)\">hope</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">you</span> <span style=\"background-color: rgba(255, 0, 0, -0.14)\">have</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">bad</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">day</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('I hope you have a bad day', pipe)\n",
    "print(pipe.predict_proba(['I hope you have a bad day']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06290301 0.93709699]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>This <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.16)\">worst</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">edit</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">ever</span>. Go <span style=\"background-color: rgba(255, 0, 0, 0.04)\">jump</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">off</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">bridge</span>.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = highlight_toxic('This is the worst edit ever. Go jump off a bridge.', pipe)\n",
    "print(pipe.predict_proba(['This is the worst edit ever. Go jump off a bridge.']))\n",
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on some random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_comments = df[df['y']==0].sample(10, random_state=seed)['comment']\n",
    "y_prob_normal = pipe.predict_proba(normal_comments)\n",
    "normal_examples = [highlight_toxic(comment, pipe) for comment in normal_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96518533 0.03481467]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "*Pursuant <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> Wikipedia:Verifiability, \"\"The <span style=\"background-color: rgba(255, 0, 0, 0.01)\">threshold</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">for</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">inclusion</span> <span style=\"background-color: rgba(255, 0, 0, -0.11)\">in</span> Wikipedia <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">verifiability</span>\"\". The <span style=\"background-color: rgba(255, 0, 0, 0.01)\">only</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">reason</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">content</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">should</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">removed</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">from</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">an</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">if</span> <span style=\"background-color: rgba(255, 0, 0, -0.12)\">it</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">cannot</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">verified</span>.  <span style=\"background-color: rgba(255, 0, 0, 0.01)\">repeated</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">removal</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">subject</span>'<span style=\"background-color: rgba(255, 0, 0, -0.04)\">s</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">must</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">stop</span>. He <span style=\"background-color: rgba(255, 0, 0, 0.03)\">is</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">deliberately</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">trying</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">compromise</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">integrity</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> Wikipedia <span style=\"background-color: rgba(255, 0, 0, -0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">ignoring</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">consensus</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> AfD <span style=\"background-color: rgba(255, 0, 0, -0.00)\">discussion</span>, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">continuing</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.04)\">edit</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">war</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">against</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">thi</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">that</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">he</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">took</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">position</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">delete</span>. The AfD <span style=\"background-color: rgba(255, 0, 0, -0.02)\">consensus</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">was</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">delete</span>. The <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">are</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">verifiable</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">they</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">should</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">removed</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">from</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">article</span>.  '<span style=\"background-color: rgba(255, 0, 0, -0.04)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">repeated</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">removal</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">such</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">acting</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">credits</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">constitutes</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">vandalism</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">pursuant</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> Wikipedia:Vandalism, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">he</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">has</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">been</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">warned</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">stop</span>.   \"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "print(y_prob_normal[i])\n",
    "HTML(normal_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = df[df['y']==1].sample(10, random_state=seed)['comment']\n",
    "y_prob_toxic = pipe.predict_proba(toxic_comments)\n",
    "toxic_examples = [highlight_toxic(comment, pipe) for comment in toxic_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40919978 0.59080022]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "\n",
       "I <span style=\"background-color: rgba(255, 0, 0, 0.03)\">suggest</span> <span style=\"background-color: rgba(255, 0, 0, 0.07)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">get</span> <span style=\"background-color: rgba(255, 0, 0, 0.08)\">some</span> <span style=\"background-color: rgba(255, 0, 0, 0.24)\">mental</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">help</span>.  </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37620651 0.62379349]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "== Hubris ==\n",
       "\n",
       "Your <span style=\"background-color: rgba(255, 0, 0, 0.02)\">unconscionable</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">hubris</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">will</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">be</span> <span style=\"background-color: rgba(255, 0, 0, 0.02)\">your</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">downfall</span>. With <span style=\"background-color: rgba(255, 0, 0, -0.07)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">simple</span> <span style=\"background-color: rgba(255, 0, 0, -0.06)\">sword</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">of</span> <span style=\"background-color: rgba(255, 0, 0, -0.02)\">truth</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">will</span> I <span style=\"background-color: rgba(255, 0, 0, 0.01)\">vanquish</span> <span style=\"background-color: rgba(255, 0, 0, 0.20)\">ye</span>. Indeed, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">woe</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">unto</span> <span style=\"background-color: rgba(255, 0, 0, 0.20)\">ye</span>, <span style=\"background-color: rgba(255, 0, 0, -0.04)\">for</span> I <span style=\"background-color: rgba(255, 0, 0, 0.01)\">wax</span> <span style=\"background-color: rgba(255, 0, 0, 0.30)\">terrible</span>, <span style=\"background-color: rgba(255, 0, 0, 0.02)\">wielding</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">blade</span>, <span style=\"background-color: rgba(255, 0, 0, 0.02)\">ready</span> <span style=\"background-color: rgba(255, 0, 0, -0.08)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">smite</span>.   </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24845623 0.75154377]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "==NPOV==\n",
       "<span style=\"background-color: rgba(255, 0, 0, 0.06)\">damnit</span>, <span style=\"background-color: rgba(255, 0, 0, -0.01)\">liberals</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">blogger</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">are</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">going</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">try</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">spin</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.52)\">hell</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">out</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">look</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">at</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">version</span> <span style=\"background-color: rgba(255, 0, 0, -0.21)\">it</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">was</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">protected</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">on</span>! Why <span style=\"background-color: rgba(255, 0, 0, 0.24)\">is</span> <span style=\"background-color: rgba(255, 0, 0, -0.04)\">something</span> <span style=\"background-color: rgba(255, 0, 0, -0.13)\">as</span> <span style=\"background-color: rgba(255, 0, 0, -0.09)\">minor</span> <span style=\"background-color: rgba(255, 0, 0, -0.13)\">as</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">hunting</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">accident</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">even</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">listed</span> <span style=\"background-color: rgba(255, 0, 0, 0.16)\">in</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">article</span>! It <span style=\"background-color: rgba(255, 0, 0, -0.06)\">reads</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">like</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">blog</span> <span style=\"background-color: rgba(255, 0, 0, -0.05)\">from</span> <span style=\"background-color: rgba(255, 0, 0, 0.09)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.27)\">freaking</span> Daily Kos, <span style=\"background-color: rgba(255, 0, 0, -0.07)\">please</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">clean</span> <span style=\"background-color: rgba(255, 0, 0, 0.14)\">this</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">up</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">conform</span> <span style=\"background-color: rgba(255, 0, 0, -0.07)\">to</span> Neutral POV, <span style=\"background-color: rgba(255, 0, 0, -0.01)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.06)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">exploit</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.09)\">minor</span> <span style=\"background-color: rgba(255, 0, 0, -0.01)\">accident</span> <span style=\"background-color: rgba(255, 0, 0, 0.05)\">like</span> <span style=\"background-color: rgba(255, 0, 0, -0.21)\">it</span>'<span style=\"background-color: rgba(255, 0, 0, -0.15)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.31)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">big</span> <span style=\"background-color: rgba(255, 0, 0, -0.03)\">deal</span>! </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.18633803e-06 9.99996814e-01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "== Gregalton: Douchemaster Supreme ==\n",
       "\n",
       "I'<span style=\"background-color: rgba(255, 0, 0, 0.00)\">m</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">an</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">editor</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">so</span> I <span style=\"background-color: rgba(255, 0, 0, -0.00)\">really</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">don</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">t</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">have</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">problem</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">calling</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>. The <span style=\"background-color: rgba(255, 0, 0, 0.00)\">fact</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">that</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">considers</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">anyone</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">who</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">criticizes</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">practice</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">of</span> FRB <span style=\"background-color: rgba(255, 0, 0, 0.00)\">as</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">non</span>-<span style=\"background-color: rgba(255, 0, 0, -0.00)\">mainstream</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">raised</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">flag</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">in</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">my</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">mind</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">that</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">is</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">made</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">me</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">check</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">discussion</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">page</span>. You'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">ve</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">done</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">more</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">to</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">bias</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">than</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">these</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">supposed</span> \"\"<span style=\"background-color: rgba(255, 0, 0, 0.00)\">conspiracy</span>\"\" <span style=\"background-color: rgba(255, 0, 0, -0.00)\">people</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">probably</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">did</span>. At <span style=\"background-color: rgba(255, 0, 0, 0.00)\">any</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">rate</span>, <span style=\"background-color: rgba(255, 0, 0, 0.01)\">fuck</span> Wikipedia, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">and</span> <span style=\"background-color: rgba(255, 0, 0, 0.01)\">fuck</span> Gregalton; I <span style=\"background-color: rgba(255, 0, 0, -0.00)\">wait</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">for</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">day</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">when</span> Knol (<span style=\"background-color: rgba(255, 0, 0, 0.00)\">google</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">s</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">wikipedia</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">written</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">experts</span>: <span style=\"background-color: rgba(255, 0, 0, 0.00)\">reality</span>, <span style=\"background-color: rgba(255, 0, 0, 0.00)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">wikiality</span>) <span style=\"background-color: rgba(255, 0, 0, 0.00)\">has</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">good</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">under</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">same</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">title</span> (<span style=\"background-color: rgba(255, 0, 0, -0.00)\">and</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">it</span>'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">s</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">written</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">by</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">one</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">these</span> \"\"<span style=\"background-color: rgba(255, 0, 0, -0.00)\">non</span>-<span style=\"background-color: rgba(255, 0, 0, -0.00)\">mainstream</span>\"\" <span style=\"background-color: rgba(255, 0, 0, -0.00)\">economists</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">the</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">article</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">talks</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">about</span>).\n",
       "\n",
       "You'<span style=\"background-color: rgba(255, 0, 0, -0.00)\">re</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>, <span style=\"background-color: rgba(255, 0, 0, -0.00)\">gregalton</span>.  A <span style=\"background-color: rgba(255, 0, 0, 0.00)\">big</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">fat</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">fractional</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">reserve</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">banking</span> <span style=\"background-color: rgba(255, 0, 0, -0.00)\">loving</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">douchebag</span>.\"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8\n",
    "print(y_prob_toxic[i])\n",
    "HTML(toxic_examples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...it seems like dropping out one token at a time isn't going to cut it. Even though the model is scoring this comment as toxic, it is having some issues highlighting specific segments. Let's dive into the model and drive highlighting by the exact contribution to each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = toxic_comments.values[8]\n",
    "features = pipe.named_steps['vect'].get_feature_names() # Don't cast this to a numpy array...\n",
    "counts = pipe.named_steps['vect'].transform([comment]).toarray().flatten()\n",
    "w = pipe.named_steps['clf'].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.9506251995001473,\n",
       " 'about': -0.2573779969605216,\n",
       " 'an': 0.24775747406102963,\n",
       " 'and': -0.26113798744752736,\n",
       " 'any': -0.04195150960840179,\n",
       " 'anyone': -0.17851617027838612,\n",
       " 'article': -0.917904310846447,\n",
       " 'as': -0.1915447073542239,\n",
       " 'at': -0.1695905146795088,\n",
       " 'banking': -0.21517154754479062,\n",
       " 'bias': 0.14695020051432892,\n",
       " 'big': 0.4201936147568579,\n",
       " 'by': -0.007789988269459465,\n",
       " 'calling': -0.004525334154367213,\n",
       " 'check': -0.32613314230385276,\n",
       " 'considers': 0.03558991071102402,\n",
       " 'conspiracy': 0.08777763038538694,\n",
       " 'criticizes': -0.022762161378118775,\n",
       " 'day': -0.07177890620233918,\n",
       " 'did': -0.23221968775288868,\n",
       " 'discussion': -0.15508429059649287,\n",
       " 'don': -0.028806586242888867,\n",
       " 'done': -0.09142575896360813,\n",
       " 'douchebag': 3.0288359785357937,\n",
       " 'economists': -0.02508670957939663,\n",
       " 'editor': -0.10446221268238955,\n",
       " 'experts': 0.04890261771595807,\n",
       " 'fact': -0.03430937874263487,\n",
       " 'fat': 1.1855633862722827,\n",
       " 'flag': 0.16822040909077168,\n",
       " 'for': 0.02230599771168577,\n",
       " 'fractional': -0.04673646030556804,\n",
       " 'frb': 0.0077160082442503065,\n",
       " 'fuck': 8.032156164072816,\n",
       " 'good': -0.23252073026801426,\n",
       " 'google': 0.317427293756958,\n",
       " 'gregalton': -0.5946911110565586,\n",
       " 'has': -0.05859799166191128,\n",
       " 'have': -0.23444319524254675,\n",
       " 'i': -0.31713152916243365,\n",
       " 'in': -0.22041271711896077,\n",
       " 'is': 0.036294802033222016,\n",
       " 'it': -0.06461719137125699,\n",
       " 'knol': -0.1069241626165296,\n",
       " 'loving': -0.04243954840495195,\n",
       " 'm': -0.012797724100646436,\n",
       " 'made': -0.18525889100486467,\n",
       " 'mainstream': -0.5541211709739405,\n",
       " 'me': 0.4273328271330389,\n",
       " 'mind': 0.11550303277330212,\n",
       " 'more': 0.04918948504446273,\n",
       " 'my': 0.31918858540680567,\n",
       " 'non': -0.2655386190167365,\n",
       " 'not': 0.2772023777712694,\n",
       " 'of': 0.06491508666760028,\n",
       " 'one': -0.1956460824759826,\n",
       " 'page': 0.13772629372601464,\n",
       " 'people': -0.09850090347813027,\n",
       " 'practice': -0.16442336899698343,\n",
       " 'probably': -0.09409650854914578,\n",
       " 'problem': 0.10170696156347236,\n",
       " 'raised': -0.08180406543765435,\n",
       " 'rate': -0.39668555095952474,\n",
       " 're': -0.023295421949223155,\n",
       " 'reality': 0.12423672047951936,\n",
       " 'really': 0.09238072426616901,\n",
       " 'reserve': -0.1336393505439358,\n",
       " 's': -0.3976797308964246,\n",
       " 'same': -0.05745187865447148,\n",
       " 'so': -0.010975581138590238,\n",
       " 'supposed': -0.22478279814643087,\n",
       " 'supreme': -0.23248713617682784,\n",
       " 't': -0.012280844708192237,\n",
       " 'talks': 0.09774048149624498,\n",
       " 'than': 0.06155289312738878,\n",
       " 'that': -0.19885068244223306,\n",
       " 'the': -1.7485590207925203,\n",
       " 'these': 0.3663171714130783,\n",
       " 'title': -0.27860169622741066,\n",
       " 'to': -0.15440880084723904,\n",
       " 'under': 0.05427985192116989,\n",
       " 've': -0.20759966159635773,\n",
       " 'wait': -0.011993668358385553,\n",
       " 'when': -0.09468607998783987,\n",
       " 'who': 0.2475689408855331,\n",
       " 'wikiality': 0.39443945983711726,\n",
       " 'wikipedia': 1.182131736417235,\n",
       " 'written': 0.16752572606676347,\n",
       " 'you': 1.5747210968102785}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(counts > 0)[0]\n",
    "weight_dict = {}\n",
    "for i in idx:\n",
    "    if len(features[i].split(' ')) == 1: # Only keep unigrams\n",
    "        weight_dict[features[i]] = w[i]*counts[i]\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '<pre>' + comment + '</pre>'\n",
    "for k,v in weight_dict.items():\n",
    "    if v < 0:\n",
    "        pass\n",
    "    else:\n",
    "        span_string = '''<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">%s</span>''' % (v,k)        \n",
    "        output = re.sub(r'\\b%s\\b' % k, span_string, output, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\"\n",
       "\n",
       "== Gregalton: Douchemaster Supreme ==\n",
       "\n",
       "I'm <span style=\"background-color: rgba(255, 0, 0, 0.28)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.25)\">an</span> editor, so I <span style=\"background-color: rgba(255, 0, 0, 0.09)\">really</span> don't have <span style=\"background-color: rgba(255, 0, 0, 0.95)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.10)\">problem</span> calling <span style=\"background-color: rgba(255, 0, 0, 1.57)\">you</span> <span style=\"background-color: rgba(255, 0, 0, 0.95)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 3.03)\">douchebag</span>. The fact that the article <span style=\"background-color: rgba(255, 0, 0, 0.04)\">considers</span> anyone <span style=\"background-color: rgba(255, 0, 0, 0.25)\">who</span> criticizes the practice <span style=\"background-color: rgba(255, 0, 0, 0.06)\">of</span> FRB as non-mainstream raised the <span style=\"background-color: rgba(255, 0, 0, 0.17)\">flag</span> in <span style=\"background-color: rgba(255, 0, 0, 0.32)\">my</span> <span style=\"background-color: rgba(255, 0, 0, 0.12)\">mind</span>, that <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span>, made <span style=\"background-color: rgba(255, 0, 0, 0.43)\">me</span> check the discussion <span style=\"background-color: rgba(255, 0, 0, 0.14)\">page</span>. You've done <span style=\"background-color: rgba(255, 0, 0, 0.05)\">more</span> to <span style=\"background-color: rgba(255, 0, 0, 0.15)\">bias</span> the article <span style=\"background-color: rgba(255, 0, 0, 0.06)\">than</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">these</span> supposed \"\"<span style=\"background-color: rgba(255, 0, 0, 0.09)\">conspiracy</span>\"\" people probably did. At any rate, <span style=\"background-color: rgba(255, 0, 0, 8.03)\">fuck</span> Wikipedia, and <span style=\"background-color: rgba(255, 0, 0, 8.03)\">fuck</span> Gregalton; I wait <span style=\"background-color: rgba(255, 0, 0, 0.02)\">for</span> the day when Knol (<span style=\"background-color: rgba(255, 0, 0, 0.32)\">google</span>'s <span style=\"background-color: rgba(255, 0, 0, 1.18)\">wikipedia</span>, <span style=\"background-color: rgba(255, 0, 0, 0.17)\">written</span> by <span style=\"background-color: rgba(255, 0, 0, 0.05)\">experts</span>: <span style=\"background-color: rgba(255, 0, 0, 0.12)\">reality</span>, <span style=\"background-color: rgba(255, 0, 0, 0.28)\">not</span> <span style=\"background-color: rgba(255, 0, 0, 0.39)\">wikiality</span>) has a good article <span style=\"background-color: rgba(255, 0, 0, 0.05)\">under</span> the same title (and it's <span style=\"background-color: rgba(255, 0, 0, 0.17)\">written</span> by one <span style=\"background-color: rgba(255, 0, 0, 0.06)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.37)\">these</span> \"\"non-mainstream\"\" economists the article <span style=\"background-color: rgba(255, 0, 0, 0.10)\">talks</span> about).\n",
       "\n",
       "You're a <span style=\"background-color: rgba(255, 0, 0, 3.03)\">douchebag</span>, gregalton.  A <span style=\"background-color: rgba(255, 0, 0, 0.42)\">big</span> <span style=\"background-color: rgba(255, 0, 0, 1.19)\">fat</span> fractional reserve banking loving douchebag.\"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the functional form of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_toxic(comment, pipe, features, w):\n",
    "    counts = pipe.named_steps['vect'].transform([comment]).toarray().flatten()\n",
    "    # Build weight dictionary (unigram only)\n",
    "    idx = np.where(counts > 0)[0]\n",
    "    weight_dict = {}\n",
    "    for i in idx:\n",
    "        if len(features[i].split(' ')) == 1: # Only keep unigrams\n",
    "            weight_dict[features[i]] = w[i]*counts[i]\n",
    "    # Scale to max value\n",
    "    \n",
    "    # Insert spans\n",
    "    output = '<pre>' + comment + '</pre>'\n",
    "    for k,v in weight_dict.items():\n",
    "        if v < 0:\n",
    "            pass\n",
    "        else:\n",
    "            # Some regex magic for keeping the original case\n",
    "            span_string = r'<span style=\"background-color: rgba(255, 0, 0, %0.2f)\">\\1</span>' % v\n",
    "            output = re.sub(r'(?i)(\\b%s\\b)' % k, span_string, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pipe.named_steps['vect'].get_feature_names()\n",
    "w = pipe.named_steps['clf'].coef_.flatten()\n",
    "toxic_examples = [highlight_toxic(comment, pipe, features, w) for comment in toxic_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "== <span style=\"background-color: rgba(255, 0, 0, 0.44)\">BONGWARRIOR</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">IS</span> <span style=\"background-color: rgba(255, 0, 0, 0.19)\">A</span> <span style=\"background-color: rgba(255, 0, 0, 0.11)\">GIGANTIC</span> <span style=\"background-color: rgba(255, 0, 0, 2.38)\">ASSHOLE</span>.  ==\n",
       "\n",
       "I WILL <span style=\"background-color: rgba(255, 0, 0, 0.03)\">DIG</span> <span style=\"background-color: rgba(255, 0, 0, 0.28)\">UP</span> <span style=\"background-color: rgba(255, 0, 0, 0.33)\">YOUR</span> GRANDMOTHER AND <span style=\"background-color: rgba(255, 0, 0, 3.07)\">SHIT</span> ON <span style=\"background-color: rgba(255, 0, 0, 0.26)\">HER</span> <span style=\"background-color: rgba(255, 0, 0, 0.00)\">DENTURES</span>.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(toxic_examples[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "==<span style=\"background-color: rgba(255, 0, 0, 0.30)\">NPOV</span>==\n",
       "<span style=\"background-color: rgba(255, 0, 0, 0.32)\">damnit</span>, <span style=\"background-color: rgba(255, 0, 0, 0.00)\">liberals</span> and <span style=\"background-color: rgba(255, 0, 0, 0.04)\">blogger</span> <span style=\"background-color: rgba(255, 0, 0, 0.26)\">are</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">going</span> to try and <span style=\"background-color: rgba(255, 0, 0, 0.13)\">spin</span> the <span style=\"background-color: rgba(255, 0, 0, 1.58)\">hell</span> <span style=\"background-color: rgba(255, 0, 0, 0.06)\">out</span> <span style=\"background-color: rgba(255, 0, 0, 0.03)\">of</span> <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span>, look at the version it was <span style=\"background-color: rgba(255, 0, 0, 0.12)\">protected</span> on! <span style=\"background-color: rgba(255, 0, 0, 0.06)\">Why</span> <span style=\"background-color: rgba(255, 0, 0, 0.04)\">is</span> something as minor as <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.21)\">hunting</span> accident even listed in <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span> article! It reads <span style=\"background-color: rgba(255, 0, 0, 0.35)\">like</span> <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.27)\">blog</span> from the <span style=\"background-color: rgba(255, 0, 0, 0.79)\">freaking</span> Daily <span style=\"background-color: rgba(255, 0, 0, 0.00)\">Kos</span>, please <span style=\"background-color: rgba(255, 0, 0, 0.02)\">clean</span> <span style=\"background-color: rgba(255, 0, 0, 0.79)\">this</span> <span style=\"background-color: rgba(255, 0, 0, 0.28)\">up</span> to <span style=\"background-color: rgba(255, 0, 0, 0.07)\">conform</span> to Neutral <span style=\"background-color: rgba(255, 0, 0, 0.02)\">POV</span>, and <span style=\"background-color: rgba(255, 0, 0, 0.14)\">not</span> exploit <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> minor accident <span style=\"background-color: rgba(255, 0, 0, 0.35)\">like</span> it's <span style=\"background-color: rgba(255, 0, 0, 0.76)\">a</span> <span style=\"background-color: rgba(255, 0, 0, 0.42)\">big</span> deal! </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(toxic_examples[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
