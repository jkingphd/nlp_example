{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import Ridge\n",
    "from IPython.display import HTML\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          0  article  random   test  0.0  1.0  0.1  0  \n",
       "3          1  article  random  train  0.0  2.0  0.6  0  \n",
       "4          1  article  random   test -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sql.connect('../data/toxic.db') as conn:\n",
    "    df = pd.read_sql_query('''select * from toxic''', conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into two seperate dataframes: df_train and df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>\"\\n\\n\\nI fixed the link; I also removed \"\"home...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>\"If they are \"\"indisputable\"\" then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "3  37330.0  \"\\n\\n\\nI fixed the link; I also removed \"\"home...  2002   \n",
       "4  37346.0  \"If they are \"\"indisputable\"\" then why does th...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          1  article  random  train  0.0  2.0  0.6  0  \n",
       "3          1  article  random  train -1.0  1.0  0.1  0  \n",
       "4          1  article  random  train -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['split'] == 'train'].copy().reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['split'] == 'test'].copy().reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab our \"best\" model from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return re.findall(r'[a-z0-9]+', text.lower())\n",
    "\n",
    "gs = load('../results/gs_cv_sgd.joblib')\n",
    "pipe = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make things easier, let's compute probabilities for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split  min  max  avg  y    y_prob  \n",
       "0          0  article  random  test  0.0  1.0  0.1  0  0.244198  \n",
       "1          1  article  random  test -1.0  1.0  0.2  0  0.172840  \n",
       "2          1  article  random  test  0.0  1.0  0.5  0  0.003700  \n",
       "3          1     user  random  test  0.0  1.0  0.4  0  0.008976  \n",
       "4          1     user  random  test  0.0  1.0  0.3  0  0.007818  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['y_prob'] = pipe.predict_proba(df_test['comment'])[:,1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global surrogates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many NLP models use complicated neural network architecture that don't exactly lend themselves well to interpretation. A global surrogate is an interpretable model (e.g., decision tree, logistic regression, k-nearest neighbors, etc.) that is trained on the output of the _true_ model. In effect, it tries to distill the complex model into a simpler one, which can have benefits for deployment as well. Our \"best\" model is a linear model, so this is a bit more direct that the process would normally be. Let's start by looking at the tokens that are most important for predicting each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.485310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0</td>\n",
       "      <td>0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 00</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 005</td>\n",
       "      <td>-0.007528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 01</td>\n",
       "      <td>-0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token    weight\n",
       "0      0 -0.485310\n",
       "1    0 0  0.039417\n",
       "2   0 00 -0.000088\n",
       "3  0 005 -0.007528\n",
       "4   0 01 -0.002821"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pipe.named_steps['vect'].get_feature_names() # Note, NOT the same as vocabulary_\n",
    "weights = pipe.named_steps['clf'].coef_[0]\n",
    "df_model = pd.DataFrame({'token':tokens, 'weight':weights})\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463216</th>\n",
       "      <td>thanks</td>\n",
       "      <td>-1.575386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127997</th>\n",
       "      <td>cool you</td>\n",
       "      <td>-1.079754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463188</th>\n",
       "      <td>thank you</td>\n",
       "      <td>-1.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220356</th>\n",
       "      <td>hey hey</td>\n",
       "      <td>-0.978156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58988</th>\n",
       "      <td>are cool</td>\n",
       "      <td>-0.958368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463160</th>\n",
       "      <td>thank</td>\n",
       "      <td>-0.863174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189578</th>\n",
       "      <td>for your</td>\n",
       "      <td>-0.836592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130100</th>\n",
       "      <td>could you</td>\n",
       "      <td>-0.775153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393418</th>\n",
       "      <td>regards</td>\n",
       "      <td>-0.771566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228178</th>\n",
       "      <td>http en</td>\n",
       "      <td>-0.759324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token    weight\n",
       "463216     thanks -1.575386\n",
       "127997   cool you -1.079754\n",
       "463188  thank you -1.015618\n",
       "220356    hey hey -0.978156\n",
       "58988    are cool -0.958368\n",
       "463160      thank -0.863174\n",
       "189578   for your -0.836592\n",
       "130100  could you -0.775153\n",
       "393418    regards -0.771566\n",
       "228178    http en -0.759324"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88865</th>\n",
       "      <td>block block</td>\n",
       "      <td>12.789651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315629</th>\n",
       "      <td>nipple nipple</td>\n",
       "      <td>11.052719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315628</th>\n",
       "      <td>nipple</td>\n",
       "      <td>10.774228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459260</th>\n",
       "      <td>teabag</td>\n",
       "      <td>9.681863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97787</th>\n",
       "      <td>buttsecks</td>\n",
       "      <td>7.755658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540505</th>\n",
       "      <td>wikipedia hi</td>\n",
       "      <td>5.545768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220792</th>\n",
       "      <td>hi wikipedia</td>\n",
       "      <td>5.399690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195137</th>\n",
       "      <td>fuck</td>\n",
       "      <td>4.016078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109999</th>\n",
       "      <td>chester</td>\n",
       "      <td>3.474630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500501</th>\n",
       "      <td>tommy2010</td>\n",
       "      <td>3.472154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                token     weight\n",
       "88865     block block  12.789651\n",
       "315629  nipple nipple  11.052719\n",
       "315628         nipple  10.774228\n",
       "459260         teabag   9.681863\n",
       "97787       buttsecks   7.755658\n",
       "540505   wikipedia hi   5.545768\n",
       "220792   hi wikipedia   5.399690\n",
       "195137           fuck   4.016078\n",
       "109999        chester   3.474630\n",
       "500501      tommy2010   3.472154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual examples\n",
    "A counterfactual explanation of a prediction describes the smallest change to the prediction instance that results in a change to a predefined output. In the context of this problem, the smallest change that induces a change from toxic to non-toxic or vice-versa. Of course, defining what constitutes a _small_ change is particularly difficult. Here are a couple basic strategies for generating those examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical comparison \n",
    "We'll start by picking a positive (toxic) example from the test set and finding the _closest_ example from the training set that had a negative (non-toxic) outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>132533129.0</td>\n",
       "      <td>\\n\\nI really do not see how i am acting immatu...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12401</th>\n",
       "      <td>204752555.0</td>\n",
       "      <td>Oh, and there are no talk page giudelines, ya...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11483</th>\n",
       "      <td>189695289.0</td>\n",
       "      <td>\\n\\nNonsense. Calzaghe is Undisputed &amp; Linear ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26730</th>\n",
       "      <td>546960141.0</td>\n",
       "      <td>\\n\\n== Fuck you ==\\n\\nFuck you you cheap whore...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>183338685.0</td>\n",
       "      <td>If I am sockpuppet so is she, same computer \\n\\n</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id                                            comment  year  \\\n",
       "8319   132533129.0  \\n\\nI really do not see how i am acting immatu...  2007   \n",
       "12401  204752555.0   Oh, and there are no talk page giudelines, ya...  2008   \n",
       "11483  189695289.0  \\n\\nNonsense. Calzaghe is Undisputed & Linear ...  2008   \n",
       "26730  546960141.0  \\n\\n== Fuck you ==\\n\\nFuck you you cheap whore...  2013   \n",
       "11074  183338685.0   If I am sockpuppet so is she, same computer \\n\\n  2008   \n",
       "\n",
       "       logged_in       ns   sample split  min  max  avg  y    y_prob  \n",
       "8319           1     user  blocked  test -2.0  1.0 -0.4  1  0.987215  \n",
       "12401          1     user  blocked  test -2.0  0.0 -0.9  1  0.988083  \n",
       "11483          1  article  blocked  test -2.0 -1.0 -1.4  1  0.999699  \n",
       "26730          1     user  blocked  test -2.0 -1.0 -1.8  1  0.999984  \n",
       "11074          1     user  blocked  test -1.0  1.0 -0.5  1  0.604105  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test_pos = (df_test['y'] == 1) & (df_test['y_prob'] > 0.5)\n",
    "df_test[idx_test_pos].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "comment = df_test.loc[13718]['comment']\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize this comment, vectorize all the negative training instances, and determine which one is the closest to the target comment. We'll start by computing [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) (actually, cosine distance, or 1 - cosine similarity) between the target comment and _all_ training comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_neg = df_train['y'] == 0\n",
    "X_train_neg = pipe.named_steps['vect'].transform(df_train.loc[idx_train_neg, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipe.named_steps['vect'].transform([comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.60\n",
      "Cosine Similarity: 0.344\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::::::::::: Okay, found a source, don't know if it's good enough, don't care. It was worth a shot. I apologize for the personal attacks to you, but I'd appreciate it if you wouldn't make sarcastic comments or making fun of what I say. \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "# cosine_dist = pairwise_distances(X_train_neg, X, metric='cosine').flatten()\n",
    "cosine_sim = cosine_similarity(X_train_neg, X).flatten()\n",
    "print('AVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_sim.argmax()][0])\n",
    "print('Cosine Similarity: %0.3f' % cosine_sim.max())\n",
    "print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[cosine_sim.argmax()] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Both are clearly talking about sources, but the second is apologetic and less confrontational. Let's look at the closest three comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.344\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::::::::::: Okay, found a source, don't know if it's good enough, don't care. It was worth a shot. I apologize for the personal attacks to you, but I'd appreciate it if you wouldn't make sarcastic comments or making fun of what I say. \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.344\n",
      "<COMMENT>\n",
      "\"\n",
      "\n",
      "== looking for a song ==\n",
      "\n",
      "I am looking for a song that I thought was by a Flock of Seagulls from obviously WAY BACK that goes \"\"Don't Change for you, Don't Change a thing for me. It was kind of punkish but made a point a it popped into my mind if anyone can help me. Thanks so much\"\n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.60\n",
      "Cosine Distance: 0.342\n",
      "<COMMENT>\n",
      " Why do people make weird exception for the title Rabbi? Don't give a person a title that needs a degree that they don't have.\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_neg, X).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples don't look particularly relevant. Let's look at the three closest positive (toxic) examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_pos = df_train['y'] == 1\n",
    "X_train_pos = pipe.named_steps['vect'].transform(df_train.loc[idx_train_pos, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.432\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I don't give a flying fuck. block me I Don't care. kiss my goddamn ass. DUSTIN Motherfucking D\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.418\n",
      "<COMMENT>\n",
      "And I don't give a damn.  \n",
      "\n",
      "\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.40\n",
      "Cosine Distance: 0.409\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "I AM SO SCARED!!!  PLEASE DON'T BLOCK ME FROM EDITING!  I DON'T KNOW WHAT I'LL DO IF I CAN'T EDIT ARTICLES!  (Actually, this was a sarcastic response to your bullshit warning, you stupid asswipe.  Like I really give a shit.  Block me, you stupid fuck.)\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_pos, X).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "#     print(df_train.loc[idx_train_pos, ['avg']].values[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy counterfactual example\n",
    "Now, instead of mining our training data for counterfactual examples, let's attempt to _create_ one by dropping word occurances from the original text until the score changes. Let's review the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps here are relatively straightforward:\n",
    "1. Using the defined vectorizer, convert the comment to a raw count vector.\n",
    "2. Create a variation for each unique token in the raw count vector, such that each variant has a single token masked.\n",
    "3. Generate a confidence score for each variant.\n",
    "4. Identify the feature that moved the base score the furthest and mask it across all other variants.\n",
    "5. Repeat until confidence score crosses threshold.\n",
    "\n",
    "We'll start by demonstrating a single iteration of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 560571)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero = np.nonzero(X.toarray().flatten())[0] # identify all nonzero elements of the target vector\n",
    "variants = np.repeat(X.toarray(), len(idx_nonzero), axis=0)\n",
    "# for each variant, mask a single feature (token)\n",
    "for i, j in enumerate(idx_nonzero):\n",
    "    variants[i,j] = 0\n",
    "variants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a prediction for each variant and identify which feature was most impactful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing token \"shit\" changes toxic score from 96.8% to 67.4%\n"
     ]
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(variants)[:,1]\n",
    "k = y_prob_var.argmin()\n",
    "print('''Removing token \"%s\" changes toxic score from %0.1f%% to %0.1f%%''' % (tokens[idx_nonzero[k]], 100*y_prob_var[0], 100*y_prob_var[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun stuff. Now let's create a function and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction_cf(comment, tokens, pipe, max_tokens=100):\n",
    "    X = pipe.named_steps['vect'].transform([comment])\n",
    "    y_prob_base = pipe.named_steps['clf'].predict_proba(X)[:,1][0]\n",
    "    idx_nonzero = np.nonzero(X.toarray().flatten())[0]\n",
    "    variants = np.repeat(X.toarray(), len(idx_nonzero), axis=0)\n",
    "    for i,j in enumerate(idx_nonzero):\n",
    "        variants[i,j] = 0\n",
    "    log = [[None, None, y_prob_base]]\n",
    "    for step in tqdm(range(max_tokens), total=float('inf')):\n",
    "        y_prob_var = pipe.named_steps['clf'].predict_proba(variants)[:,1]\n",
    "        k = y_prob_var.argsort()[step]\n",
    "#         print(k, tokens[idx_nonzero[k]], y_prob_var[k])\n",
    "        variants[:,idx_nonzero[k]] = 0\n",
    "        log.append([k, tokens[idx_nonzero[k]], y_prob_var[k]])\n",
    "        if y_prob_var[k] < 0.5:\n",
    "            break\n",
    "    return log, y_prob_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None, None, 0.9780473453499616],\n",
       " [27, 'shit', 0.6740743903054798],\n",
       " [22, 'me', 0.5742807959783442],\n",
       " [14, 'give a', 0.4841897354143122]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log, y_prob_base = explain_prediction_cf(comment, tokens, pipe)\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's format this for ease of consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf(comment, tokens, pipe):\n",
    "    log, y_prob_base = explain_prediction_cf(comment, tokens, pipe)\n",
    "    html = '<pre><h2>Explanation</h2>\\n'\n",
    "    html += 'Removing {'\n",
    "    for row in log[1:]:\n",
    "        html += '\"%s\", ' % row[1]\n",
    "    html = html[:-2]\n",
    "    html += '} from the text changes the toxicity score from %0.1f%% to %0.1f%%.' % (100*log[0][2], 100*log[-1][2])\n",
    "    # Now let's add the original comment with highlighted text\n",
    "    for row in log[1:]:\n",
    "        token = row[1]\n",
    "        comment = re.sub(r'\\b%s\\b' % token, '<span style=\"background-color: rgba(255, 0, 0, 0.2)\">%s</span>' % token, comment, flags=re.IGNORECASE)  \n",
    "    html += '<h2>Original</h2>\\n%s</pre>' % comment\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><h2>Explanation</h2>\n",
       "Removing {\"shit\", \"me\", \"give a\"} from the text changes the toxicity score from 97.8% to 48.4%.<h2>Original</h2>\n",
       "\"\n",
       "::Block <span style=\"background-color: rgba(255, 0, 0, 0.2)\">me</span>. I really don't <span style=\"background-color: rgba(255, 0, 0, 0.2)\">give a</span> <span style=\"background-color: rgba(255, 0, 0, 0.2)\">shit</span>! If a source doesn't work for someone, it gets removed. K?    \"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(get_cf(comment, tokens, pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 8 August 2009 (UTC)\n",
      "\n",
      "\n",
      "I just saw Xeno's edit comment - A Phone Call????? That's a reliable source that verified it for you???? You're a lousy editor, biased, obstructionist and fixed on defending your article. Fact is the claim was unsupported and unverified and should not be in here until such time as a Reliable Source was produced. You've been completely unable and incapable of providing a source yet more than happy to keep your edit by any means possible. Absolute garbage - and I detest your unsupported allegations that I'm a fucking teabagger, Republican or one-subject editor -ESPECIALLY since I provided supporting links to my NPOV editing. This is how you support an edit: You give it a proper name: Suncoast Regional Emmy Award /You give it a year: 2000. /You give it a title: A Grave Injustice /You give it a channel: WDSU, New Orleans - AND YOU PROVIDE A RELIABLE SOURCE: And you do it without bias according to supporting references. Your a biased hack, your attacks, ignorance, incompetence and obstructionism did nothing to better this article, they only serve to drive those you bully away from the project. Don't be a Dick. Oh, and the last 1/2 of the article is garbage fluff that serves no purpose other than to keep the guards and gatekeepers employed. But then anyone who takes issue with your precious must be a Republican Secret Agent bent on who knows what fantasy exists in your mind. And yes, your dickishness here does piss off us neutral editors. Like myself, editing NPOV since '01.  04:38\n"
     ]
    }
   ],
   "source": [
    "comment_2 = df_test.loc[17621, 'comment']\n",
    "print(comment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><h2>Explanation</h2>\n",
       "Removing {\"you\", \"garbage\", \"your\", \"piss\", \"a dick\", \"re a\", \"off\", \"oh\"} from the text changes the toxicity score from 100.0% to 36.2%.<h2>Original</h2>\n",
       ", 8 August 2009 (UTC)\n",
       "\n",
       "\n",
       "I just saw Xeno's edit comment - A Phone Call????? That's a reliable source that verified it for <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>???? <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>'<span style=\"background-color: rgba(255, 0, 0, 0.2)\">re a</span> lousy editor, biased, obstructionist and fixed on defending <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> article. Fact is the claim was unsupported and unverified and should not be in here until such time as a Reliable Source was produced. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span>'ve been completely unable and incapable of providing a source yet more than happy to keep <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> edit by any means possible. Absolute <span style=\"background-color: rgba(255, 0, 0, 0.2)\">garbage</span> - and I detest <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> unsupported allegations that I'm a fucking teabagger, Republican or one-subject editor -ESPECIALLY since I provided supporting links to my NPOV editing. This is how <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> support an edit: <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a proper name: Suncoast Regional Emmy Award /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a year: 2000. /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a title: A Grave Injustice /<span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> give it a channel: WDSU, New Orleans - AND <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> PROVIDE A RELIABLE SOURCE: And <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> do it without bias according to supporting references. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> a biased hack, <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> attacks, ignorance, incompetence and obstructionism did nothing to better this article, they only serve to drive those <span style=\"background-color: rgba(255, 0, 0, 0.2)\">you</span> bully away from the project. Don't be <span style=\"background-color: rgba(255, 0, 0, 0.2)\">a dick</span>. <span style=\"background-color: rgba(255, 0, 0, 0.2)\">oh</span>, and the last 1/2 of the article is <span style=\"background-color: rgba(255, 0, 0, 0.2)\">garbage</span> fluff that serves no purpose other than to keep the guards and gatekeepers employed. But then anyone who takes issue with <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> precious must be a Republican Secret Agent bent on who knows what fantasy exists in <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> mind. And yes, <span style=\"background-color: rgba(255, 0, 0, 0.2)\">your</span> dickishness here does <span style=\"background-color: rgba(255, 0, 0, 0.2)\">piss</span> <span style=\"background-color: rgba(255, 0, 0, 0.2)\">off</span> us neutral editors. Like myself, editing NPOV since '01.  04:38</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(get_cf(comment_2, tokens, pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Surrogate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local surrogate models are interpretable models (e.g., Logistic Regression, Decision Tree, etc.) that are used to explain individual predictions of black box machine learning models. The steps for computing a local surrogate model are as follows:\n",
    "\n",
    "1. Generate variants by randomly masking (blanking) features found in the base instance.\n",
    "2. Compute distance between base instance and each variant.\n",
    "3. Compute scores for each variant.\n",
    "4. Train an interpretable model using the inverse distance as the sample weight.\n",
    "5. Interpret the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by vectorizing the comment (base instance) and randomly masking features from it to create variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13683,  18982,  19217,  88832,  88962, 152681, 152682, 153245,\n",
       "       153256, 186689, 189069, 201036, 201126, 201907, 201909, 229569,\n",
       "       230727, 232375, 232385, 254303, 255014, 262939, 290807, 291167,\n",
       "       388853, 389014, 396308, 424082, 424153, 435431, 435600, 437394,\n",
       "       437507, 454940, 455496, 456398, 547563, 547652])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pipe.named_steps['vect'].transform([comment]).toarray()\n",
    "idx_nonzero = np.nonzero(X.flatten())[0]\n",
    "idx_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the nonzero elements in the feature vector. Now we can generate a binary mask to create the variants. Let's create 100 variants with a 20% dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.random.choice([0,1], size=(100, idx_nonzero.shape[0]), p=[0.2,0.8])\n",
    "mask[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1],\n",
       "       [2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var = np.repeat(X, repeats=100, axis=0)\n",
    "X_var[:, idx_nonzero] = mask*X_var[:, idx_nonzero]\n",
    "X_var[:2][:,idx_nonzero]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the differences between variants. Now we compute the cosine similarity between the base instance and each variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87904907, 0.90453403, 0.95346259, 0.8660254 , 0.90453403])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = cosine_similarity(X_var, X).flatten()\n",
    "sim[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll compute the confidence score for each variant using the original model (black box)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58270181, 0.97692936, 0.97699281, 0.98281699, 0.98003753])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(X_var)[:,1]\n",
    "y_prob_var[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to train the local surrogate. We'll use a ridge regression model (Linear regression w/ L2 penalty) and weight each sample by it's similarity to the base instance. Remember, we want the local surrogate to replicate the behavior of the black box model in the region of the base instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=101, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model = Ridge(random_state=seed)\n",
    "local_model.fit(X_var, y_prob_var, sample_weight=sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a local surrogate model that we can examine to better understand factors *important to this prediction*. Let's start by looking at the features associated with a negative result (non-toxic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547563</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.034859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437507</th>\n",
       "      <td>source doesn</td>\n",
       "      <td>-0.020377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254303</th>\n",
       "      <td>it</td>\n",
       "      <td>-0.015024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232385</th>\n",
       "      <td>if a</td>\n",
       "      <td>-0.014162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291167</th>\n",
       "      <td>me i</td>\n",
       "      <td>-0.013288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token      coef\n",
       "547563          work -0.034859\n",
       "437507  source doesn -0.020377\n",
       "254303            it -0.015024\n",
       "232385          if a -0.014162\n",
       "291167          me i -0.013288"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local = pd.DataFrame({'token':tokens, 'coef':local_model.coef_.flatten()})\n",
    "df_local.sort_values('coef', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just flip the order to view the features associated with a positive result (toxic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424082</th>\n",
       "      <td>shit</td>\n",
       "      <td>0.329376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88832</th>\n",
       "      <td>block</td>\n",
       "      <td>0.053366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152682</th>\n",
       "      <td>doesn t</td>\n",
       "      <td>0.031191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290807</th>\n",
       "      <td>me</td>\n",
       "      <td>0.030523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255014</th>\n",
       "      <td>it gets</td>\n",
       "      <td>0.024395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token      coef\n",
       "424082     shit  0.329376\n",
       "88832     block  0.053366\n",
       "152682  doesn t  0.031191\n",
       "290807       me  0.030523\n",
       "255014  it gets  0.024395"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.sort_values('coef', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just clean these steps up and create a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_surrogate(comment, tokens, pipe, num_variants=100, dropout=0.2):\n",
    "    X = pipe.named_steps['vect'].transform([comment]).toarray()\n",
    "    idx_nonzero = np.nonzero(X.flatten())[0]\n",
    "    mask = np.random.choice([0,1], size=(num_variants, idx_nonzero.shape[0]), p=[dropout,1-dropout])\n",
    "    X_var = np.repeat(X, repeats=num_variants, axis=0)\n",
    "    X_var[:, idx_nonzero] = mask*X_var[:, idx_nonzero]\n",
    "    sim = cosine_similarity(X_var, X).flatten()\n",
    "    y_prob_var = pipe.named_steps['clf'].predict_proba(X_var)[:,1]\n",
    "    local_model = Ridge(random_state=seed)\n",
    "    local_model.fit(X_var, y_prob_var, sample_weight=sim)\n",
    "    df_local = pd.DataFrame({'token':tokens, 'coef':local_model.coef_.flatten()})\n",
    "    return local_model, df_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 8 August 2009 (UTC)\n",
      "\n",
      "\n",
      "I just saw Xeno's edit comment - A Phone Call????? That's a reliable source that verified it for you???? You're a lousy editor, biased, obstructionist and fixed on defending your article. Fact is the claim was unsupported and unverified and should not be in here until such time as a Reliable Source was produced. You've been completely unable and incapable of providing a source yet more than happy to keep your edit by any means possible. Absolute garbage - and I detest your unsupported allegations that I'm a fucking teabagger, Republican or one-subject editor -ESPECIALLY since I provided supporting links to my NPOV editing. This is how you support an edit: You give it a proper name: Suncoast Regional Emmy Award /You give it a year: 2000. /You give it a title: A Grave Injustice /You give it a channel: WDSU, New Orleans - AND YOU PROVIDE A RELIABLE SOURCE: And you do it without bias according to supporting references. Your a biased hack, your attacks, ignorance, incompetence and obstructionism did nothing to better this article, they only serve to drive those you bully away from the project. Don't be a Dick. Oh, and the last 1/2 of the article is garbage fluff that serves no purpose other than to keep the guards and gatekeepers employed. But then anyone who takes issue with your precious must be a Republican Secret Agent bent on who knows what fantasy exists in your mind. And yes, your dickishness here does piss off us neutral editors. Like myself, editing NPOV since '01.  04:38\n"
     ]
    }
   ],
   "source": [
    "print(comment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195335</th>\n",
       "      <td>fucking</td>\n",
       "      <td>0.003043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263612</th>\n",
       "      <td>keep</td>\n",
       "      <td>0.002996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452417</th>\n",
       "      <td>support an</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163150</th>\n",
       "      <td>emmy</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118364</th>\n",
       "      <td>comment a</td>\n",
       "      <td>0.002798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token      coef\n",
       "195335     fucking  0.003043\n",
       "263612        keep  0.002996\n",
       "452417  support an  0.002920\n",
       "163150        emmy  0.002842\n",
       "118364   comment a  0.002798"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model, df_local = get_local_surrogate(comment_2, tokens, pipe, 100)\n",
    "df_local.sort_values('coef', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this method is very much subject to RNG. The longer your text, the more variants are required to effectively sample the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195335</th>\n",
       "      <td>fucking</td>\n",
       "      <td>0.034493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559236</th>\n",
       "      <td>your unsupported</td>\n",
       "      <td>0.022984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362502</th>\n",
       "      <td>phone call</td>\n",
       "      <td>0.021960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552883</th>\n",
       "      <td>year</td>\n",
       "      <td>0.021199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488794</th>\n",
       "      <td>this is</td>\n",
       "      <td>0.019682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   token      coef\n",
       "195335           fucking  0.034493\n",
       "559236  your unsupported  0.022984\n",
       "362502        phone call  0.021960\n",
       "552883              year  0.021199\n",
       "488794           this is  0.019682"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model, df_local = get_local_surrogate(comment_2, tokens, pipe, 200)\n",
    "df_local.sort_values('coef', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276688</th>\n",
       "      <td>links</td>\n",
       "      <td>0.037561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195335</th>\n",
       "      <td>fucking</td>\n",
       "      <td>0.028824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80768</th>\n",
       "      <td>been completely</td>\n",
       "      <td>0.027754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72689</th>\n",
       "      <td>away from</td>\n",
       "      <td>0.025457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463070</th>\n",
       "      <td>than to</td>\n",
       "      <td>0.021284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  token      coef\n",
       "276688            links  0.037561\n",
       "195335          fucking  0.028824\n",
       "80768   been completely  0.027754\n",
       "72689         away from  0.025457\n",
       "463070          than to  0.021284"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model, df_local = get_local_surrogate(comment_2, tokens, pipe, 500)\n",
    "df_local.sort_values('coef', ascending=False).head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
