{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3C-jkk-counterfactuals\n",
    "\n",
    "In this notebook, we will explore counterfactual explanations. A counterfactual explanation of a prediction describes the smallest shange to the feature values that changes the prediction to a predefined output. Counterfactual explanations can be model-specific of model-agnostic. We will focus on model-agnostic methods.\n",
    "\n",
    "Note that the documentation linked above may refer to a newer version of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import HTML\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import load\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>num</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split   num  min  max  avg  y  \n",
       "0          1  article  random  train  10.0 -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  10.0  0.0  2.0  0.5  0  \n",
       "2          0  article  random   test  10.0  0.0  1.0  0.1  0  \n",
       "3          1  article  random  train  10.0  0.0  2.0  0.6  0  \n",
       "4          1  article  random   test  10.0 -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sql.connect('../data/toxic.db') as conn:\n",
    "    df = pd.read_sql_query('''select * from toxic''', conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into two seperate dataframes: df_train and df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>num</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>\"\\n\\n\\nI fixed the link; I also removed \"\"home...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>\"If they are \"\"indisputable\"\" then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "3  37330.0  \"\\n\\n\\nI fixed the link; I also removed \"\"home...  2002   \n",
       "4  37346.0  \"If they are \"\"indisputable\"\" then why does th...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split   num  min  max  avg  y  \n",
       "0          1  article  random  train  10.0 -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  10.0  0.0  2.0  0.5  0  \n",
       "2          1  article  random  train  10.0  0.0  2.0  0.6  0  \n",
       "3          1  article  random  train  10.0 -1.0  1.0  0.1  0  \n",
       "4          1  article  random  train  10.0 -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['split'] == 'train'].copy().reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>num</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split   num  min  max  avg  y  \n",
       "0          0  article  random  test  10.0  0.0  1.0  0.1  0  \n",
       "1          1  article  random  test  10.0 -1.0  1.0  0.2  0  \n",
       "2          1  article  random  test  10.0  0.0  1.0  0.5  0  \n",
       "3          1     user  random  test  10.0  0.0  1.0  0.4  0  \n",
       "4          1     user  random  test  10.0  0.0  1.0  0.3  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['split'] == 'test'].copy().reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab our best Random Forest model from notebook 2C-jkk-random-forest. This is a good example, since predictions from a Random Forest can be difficult to intepret. Also, this model pipeline has a dense vector representation, which will be useful for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "          ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='[a-z]+', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('nmf',\n",
       "  NMF(alpha=0.0, beta_loss='frobenius', init='nndsvda', l1_ratio=0.0,\n",
       "    max_iter=200, n_components=100, random_state=None, shuffle=False,\n",
       "    solver='cd', tol=0.0001, verbose=0)),\n",
       " ('clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "              criterion='gini', max_depth=20, max_features='auto',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, n_jobs=2, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = load('../results/rs_cv_nmf_rf.joblib')\n",
    "pipe = rs.best_estimator_\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's go ahead and generate predictions on the test set so we have some examples for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>num</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>\"\\n\\n\\n\\nI'm not sure if it's properly called ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>\\n\\n\\n \\nThanks on the info on how to move a p...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>\"\\n\\n: I should do that too, I agree, but I've...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rev_id                                            comment  year  \\\n",
       "0    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "2  138074.0  \"\\n\\n\\n\\nI'm not sure if it's properly called ...  2002   \n",
       "3  200664.0  \\n\\n\\n \\nThanks on the info on how to move a p...  2002   \n",
       "4  213105.0  \"\\n\\n: I should do that too, I agree, but I've...  2002   \n",
       "\n",
       "   logged_in       ns  sample split   num  min  max  avg  y    y_prob  y_pred  \n",
       "0          0  article  random  test  10.0  0.0  1.0  0.1  0  0.322735       0  \n",
       "1          1  article  random  test  10.0 -1.0  1.0  0.2  0  0.184302       0  \n",
       "2          1  article  random  test  10.0  0.0  1.0  0.5  0  0.184865       0  \n",
       "3          1     user  random  test  10.0  0.0  1.0  0.4  0  0.084335       0  \n",
       "4          1     user  random  test  10.0  0.0  1.0  0.3  0  0.196685       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"y_prob\"] = pipe.predict_proba(df_test[\"comment\"])[:,1]\n",
    "df_test[\"y_pred\"] = (df_test[\"y_prob\"] > 0.5).astype(int)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a positive (toxic) example from the test set and find the *most similar* comment with a negative (non-toxic) label from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>num</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22019</th>\n",
       "      <td>410026490.0</td>\n",
       "      <td>I am a huge tool bag.</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>8357736.0</td>\n",
       "      <td>\\n\\nYou are a child.</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>248946653.0</td>\n",
       "      <td>\"\\n\\n== FUCK YOU ==\\nFUCK YOU!!!  YOU'RE A STU...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>395850174.0</td>\n",
       "      <td>\\n\\n== no worries ==\\n\\nWe will use another ac...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>508305880.0</td>\n",
       "      <td>\\nYou LOVE Anime!? There are some ANIMES out t...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>209435370.0</td>\n",
       "      <td>\\n\\nDON'T YOU FUCKING TOUCH MY EDITS AGAIN!!!!!</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12674</th>\n",
       "      <td>209021397.0</td>\n",
       "      <td>\\n\\n==  I hate you , unfriends !  ==\\n\\n \\n I ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29191</th>\n",
       "      <td>618375751.0</td>\n",
       "      <td>\\n:There was nothing but good intent. You plac...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24009</th>\n",
       "      <td>462241410.0</td>\n",
       "      <td>\\n\\n\\nfarooq abdullah is better known as faroo...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>163442321.0</td>\n",
       "      <td>\\n\\n\\nWhere do you get off deleting that? it t...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id                                            comment  year  \\\n",
       "22019  410026490.0                             I am a huge tool bag.   2011   \n",
       "232      8357736.0                             \\n\\nYou are a child.    2004   \n",
       "14834  248946653.0  \"\\n\\n== FUCK YOU ==\\nFUCK YOU!!!  YOU'RE A STU...  2008   \n",
       "21476  395850174.0  \\n\\n== no worries ==\\n\\nWe will use another ac...  2010   \n",
       "25681  508305880.0  \\nYou LOVE Anime!? There are some ANIMES out t...  2012   \n",
       "12701  209435370.0    \\n\\nDON'T YOU FUCKING TOUCH MY EDITS AGAIN!!!!!  2008   \n",
       "12674  209021397.0  \\n\\n==  I hate you , unfriends !  ==\\n\\n \\n I ...  2008   \n",
       "29191  618375751.0  \\n:There was nothing but good intent. You plac...  2014   \n",
       "24009  462241410.0  \\n\\n\\nfarooq abdullah is better known as faroo...  2011   \n",
       "9941   163442321.0  \\n\\n\\nWhere do you get off deleting that? it t...  2007   \n",
       "\n",
       "       logged_in       ns   sample split   num  min  max  avg  y    y_prob  \\\n",
       "22019          1     user  blocked  test  10.0 -1.0  1.0 -0.1  1  0.959228   \n",
       "232            1     user  blocked  test  10.0 -1.0  1.0 -0.1  1  0.982558   \n",
       "14834          0     user  blocked  test  10.0 -2.0 -1.0 -1.8  1  0.965476   \n",
       "21476          1     user  blocked  test  10.0 -1.0  1.0 -0.8  1  0.821475   \n",
       "25681          0     user  blocked  test  10.0 -2.0 -1.0 -1.2  1  0.835931   \n",
       "12701          0     user  blocked  test  10.0 -2.0  0.0 -1.4  1  0.849820   \n",
       "12674          1     user  blocked  test  10.0 -2.0  0.0 -0.9  1  0.957991   \n",
       "29191          0     user  blocked  test  10.0 -1.0  0.0 -0.9  1  0.708681   \n",
       "24009          0  article  blocked  test  10.0 -2.0  0.0 -0.9  1  0.606574   \n",
       "9941           1     user  blocked  test  10.0 -2.0  0.0 -1.3  1  0.919241   \n",
       "\n",
       "       y_pred  \n",
       "22019       1  \n",
       "232         1  \n",
       "14834       1  \n",
       "21476       1  \n",
       "25681       1  \n",
       "12701       1  \n",
       "12674       1  \n",
       "29191       1  \n",
       "24009       1  \n",
       "9941        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test_pos = (df_test['y'] == 1) & (df_test['y_prob'] > 0.5)\n",
    "df_test[idx_test_pos].sample(10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DON'T YOU FUCKING TOUCH MY EDITS AGAIN!!!!!\n"
     ]
    }
   ],
   "source": [
    "comment = df_test.loc[12701]['comment']\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, this comment sucks. Now we need to make a decision about computing similarity, and what it means to have similar comments. The obvious solution is to transform the comments in the training set into TF-IDF vectors and compute a pairwise distance metric, such as cosine similarity. Let's start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<77903x81017 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7826131 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train_neg = df_train[\"y\"] == 0 \n",
    "X_train_neg = pipe.named_steps[\"vect\"].transform(df_train.loc[idx_train_neg, \"comment\"])\n",
    "X_train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x81017 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target = pipe.named_steps[\"vect\"].transform([comment])\n",
    "X_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.50\n",
      "Cosine Similarity: 0.326\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::I didn't break 3RR check my edits again. Regards.  \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_neg, X_target).flatten()\n",
    "print('AVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_sim.argmax()][0])\n",
    "print('Cosine Similarity: %0.3f' % cosine_sim.max())\n",
    "print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[cosine_sim.argmax()] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, both are talking about edits, but the second is clearly much less confrontational. Let's look at the cloest three comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: 0.50\n",
      "Cosine Distance: 0.326\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "::I didn't break 3RR check my edits again. Regards.  \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.50\n",
      "Cosine Distance: 0.284\n",
      "<COMMENT>\n",
      "\n",
      ":I agree. Why don't You? \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.50\n",
      "Cosine Distance: 0.246\n",
      "<COMMENT>\n",
      "\n",
      ": Why don't you do it?   \n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_neg, X_target).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too close. What about similar *positive* examples? What do those look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_pos = df_train['y'] == 1\n",
    "X_train_pos = pipe.named_steps['vect'].transform(df_train.loc[idx_train_pos, 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -0.50\n",
      "Cosine Distance: 0.570\n",
      "<COMMENT>\n",
      " never touch my edits again you douche bag\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -0.50\n",
      "Cosine Distance: 0.451\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "Dont touch my edits you anti dentite.\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -0.50\n",
      "Cosine Distance: 0.444\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "Please touch my johnson\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_pos, X_target).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that might be obvious at this point is that we are looking for hard matches across individual tokens. However, we really care about *semantic similarity*. A topic model like NMF may produce higher quality similarity comparisons. Let's transform our data into NMF space and examine the same case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00894929, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.01186398],\n",
       "       [0.00507612, 0.00100739, 0.        , ..., 0.01329248, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00875505, 0.        , 0.        , ..., 0.        , 0.00279743,\n",
       "        0.040765  ],\n",
       "       ...,\n",
       "       [0.00346846, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00084756],\n",
       "       [0.0149903 , 0.        , 0.        , ..., 0.00349148, 0.00444417,\n",
       "        0.00116728],\n",
       "       [0.00388735, 0.        , 0.        , ..., 0.00017346, 0.        ,\n",
       "        0.00705176]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train_neg = df_train[\"y\"] == 0 \n",
    "X_train_neg = pipe.named_steps[\"nmf\"].transform(pipe.named_steps[\"vect\"].transform(df_train.loc[idx_train_neg, \"comment\"]))\n",
    "X_train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.87493940e-04,\n",
       "        1.03695513e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.09769443e-02, 0.00000000e+00, 0.00000000e+00, 1.74427504e-04,\n",
       "        1.80820986e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.82862593e-05, 0.00000000e+00,\n",
       "        5.10910738e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.67402779e-02,\n",
       "        7.25922862e-04, 0.00000000e+00, 0.00000000e+00, 3.61699484e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.35360097e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.57482865e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.06150367e-04,\n",
       "        0.00000000e+00, 3.43950319e-05, 1.76455212e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.20723448e-05, 1.46352010e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.27162403e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.98546484e-03, 4.29975340e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target = pipe.named_steps[\"nmf\"].transform(pipe.named_steps[\"vect\"].transform([comment]))\n",
    "X_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: 0.00\n",
      "Cosine Distance: 0.670\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "how does a piece of dust start sensing light tho? \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.00\n",
      "Cosine Distance: 0.659\n",
      "<COMMENT>\n",
      "piece of information \n",
      "<COMMENT>\n",
      "\n",
      "AVG: 0.00\n",
      "Cosine Distance: 0.657\n",
      "<COMMENT>\n",
      "\"Holy longest hatnote ever batman! –  \n",
      ":::::::\"\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_neg, X_target).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_neg, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_neg, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.73369885e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.88252173e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 5.85668173e-05, 6.13222676e-04],\n",
       "       [7.88262217e-03, 6.78617861e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.85360957e-03, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        2.18057329e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.98596227e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train_pos = df_train[\"y\"] == 1 \n",
    "X_train_pos = pipe.named_steps[\"nmf\"].transform(pipe.named_steps[\"vect\"].transform(df_train.loc[idx_train_pos, \"comment\"]))\n",
    "X_train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG: -1.60\n",
      "Cosine Distance: 0.978\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "Don't post on my profile page, you fucking cunt.    \n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.60\n",
      "Cosine Distance: 0.945\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "==HEY ALAN!==\n",
      "YOU FUCKING SUCK MY DICK, you gayboy. suck it hard and choke on it. don't ban me, please...\n",
      "<COMMENT>\n",
      "\n",
      "AVG: -1.60\n",
      "Cosine Distance: 0.944\n",
      "<COMMENT>\n",
      "\n",
      "\n",
      "Suck my cock you stupid bitch!:)\n",
      "<COMMENT>\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(X_train_pos, X_target).flatten()\n",
    "for i in cosine_sim.argsort()[-3:][::-1]:\n",
    "    print('\\nAVG: %0.2f' % df_train.loc[idx_train_pos, ['avg']].values[cosine_sim.argmax()][0])\n",
    "    print('Cosine Distance: %0.3f' % cosine_sim[i])\n",
    "    print('<COMMENT>\\n' + df_train.loc[idx_train_pos, 'comment'].values[i] + '\\n<COMMENT>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's talk about an alternative technique, since it may not always be feasible, legal, or advisable to provide counterfactual examples from your training set. Let's instead *create* a counterfactual example by dropping word occurances from the original text until the score flips across the threshold. Let's grab a new example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "::Block me. I really don't give a shit! If a source doesn't work for someone, it gets removed. K?    \"\n"
     ]
    }
   ],
   "source": [
    "comment = df_test.loc[13718]['comment']\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps here are relatively straightforward:\n",
    "\n",
    "  1. Using the defined vectorizer, convert the comment to a raw count vector.\n",
    "  2. Create a variation for each unique token in the raw count vector, such that each variant has a single token masked.\n",
    "  3. Generate a confidence score for each variant.\n",
    "  4. Identify the feature that moved the base score the furthest and mask it across all other variants.\n",
    "  5. Repeat until confidence score crosses threshold.\n",
    "\n",
    "We'll start by demonstrating a single iteration of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x81017 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target = pipe.named_steps['vect'].transform([comment])\n",
    "X_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 81017)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero = np.nonzero(X_target.toarray().flatten())[0] # identify all nonzero elements of the target vector\n",
    "variants = np.repeat(X_target.toarray(), len(idx_nonzero), axis=0)\n",
    "# for each variant, mask a single feature (token)\n",
    "for i, j in enumerate(idx_nonzero):\n",
    "    variants[i,j] = 0\n",
    "variants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a prediction for each variant and identify which feature was most impactful. We also need a lookup dictionary for tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.array(pipe.named_steps['vect'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing token \"shit\" changes toxic score from 77.1% to 62.9%\n"
     ]
    }
   ],
   "source": [
    "y_prob_var = pipe.named_steps['clf'].predict_proba(pipe.named_steps['nmf'].transform(variants))[:,1]\n",
    "k = y_prob_var.argmin()\n",
    "print('''Removing token \"%s\" changes toxic score from %0.1f%% to %0.1f%%''' % (tokens[idx_nonzero[k]], 100*y_prob_var[0], 100*y_prob_var[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I think that makes sense. Let's write a helper function to automate this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = pipe.named_steps['vect']\n",
    "nmf = pipe.named_steps['nmf']\n",
    "clf = pipe.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction_cf(comment, tokens=tokens, vect=vect, nmf=nmf, clf=clf, max_tokens=100):\n",
    "    X = vect.transform([comment])\n",
    "    y_prob_base = clf.predict_proba(nmf.transform(X))[:,1][0]\n",
    "    idx_nonzero = np.nonzero(X.toarray().flatten())[0]\n",
    "    variants = np.repeat(X.toarray(), len(idx_nonzero), axis=0)\n",
    "    for i,j in enumerate(idx_nonzero):\n",
    "        variants[i,j] = 0\n",
    "    log = [[None, None, y_prob_base]]\n",
    "    max_steps = np.min([len(variants), max_tokens])\n",
    "    for step in tqdm(range(max_steps)):\n",
    "        y_prob_var = clf.predict_proba(nmf.transform(variants))[:,1]\n",
    "        k = y_prob_var.argsort()[step]\n",
    "#         print(k, tokens[idx_nonzero[k]], y_prob_var[k])\n",
    "        variants[:,idx_nonzero[k]] = 0\n",
    "        log.append([k, tokens[idx_nonzero[k]], y_prob_var[k]])\n",
    "        if y_prob_var[k] < 0.5:\n",
    "            break\n",
    "    return log, y_prob_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61073bbb162244279a6a0fd3dbf3dd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([[None, None, 0.7694893640870398],\n",
       "  [32, 'shit', 0.6290851245473555],\n",
       "  [16, 'give a', 0.5482100796290866],\n",
       "  [17, 'give a shit', 0.4901658935061039]],\n",
       " 0.7694893640870398)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_prediction_cf(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf(comment, log, y_prob_base):\n",
    "    html = '<pre><h2>Explanation</h2>\\n'\n",
    "    html += 'Removing {'\n",
    "    for row in log[1:]:\n",
    "        html += '\"%s\", ' % row[1]\n",
    "    html = html[:-2]\n",
    "    html += '} from the text changes the toxicity score from %0.1f%% to %0.1f%%.' % (100*log[0][2], 100*log[-1][2])\n",
    "    # Now let's add the original comment with highlighted text\n",
    "    for row in log[1:]:\n",
    "        token = row[1]\n",
    "        comment = re.sub(r'\\b%s\\b' % token, '<span style=\"background-color: rgba(255, 0, 0, 0.2)\">%s</span>' % token, comment, flags=re.IGNORECASE)  \n",
    "    html += '<h2>Original</h2>\\n%s</pre>' % comment\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de663b842804c7ea631613ceed6f057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><h2>Explanation</h2>\n",
       "Removing {\"shit\", \"give a\", \"give a shit\"} from the text changes the toxicity score from 76.9% to 49.0%.<h2>Original</h2>\n",
       "\"\n",
       "::Block me. I really don't <span style=\"background-color: rgba(255, 0, 0, 0.2)\">give a</span> <span style=\"background-color: rgba(255, 0, 0, 0.2)\">shit</span>! If a source doesn't work for someone, it gets removed. K?    \"</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log, y_prob_base = explain_prediction_cf(comment)\n",
    "HTML(get_cf(comment, log, y_prob_base))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_intro]",
   "language": "python",
   "name": "conda-env-nlp_intro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
