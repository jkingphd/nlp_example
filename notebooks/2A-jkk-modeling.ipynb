{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:\\n:One can make an analogy in mathematica...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>\"\\n\\n:Clarification for you  (and Zundark's ri...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>\"This is such a fun entry.   Devotchka\\n\\nI on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:\\n:One can make an analogy in mathematica...  2002   \n",
       "1   4216.0  \"\\n\\n:Clarification for you  (and Zundark's ri...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  \"This is such a fun entry.   Devotchka\\n\\nI on...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  min  max  avg  y  \n",
       "0          1  article  random  train -1.0  1.0  0.4  0  \n",
       "1          1     user  random  train  0.0  2.0  0.5  0  \n",
       "2          0  article  random   test  0.0  1.0  0.1  0  \n",
       "3          1  article  random  train  0.0  2.0  0.6  0  \n",
       "4          1  article  random   test -1.0  1.0  0.2  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sql.connect('../data/toxic.db') as conn:\n",
    "    df = pd.read_sql_query('select * from toxic', conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to isolate the train, dev, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = df['split'] == 'train'\n",
    "idx_dev = df['split'] == 'dev'\n",
    "idx_test = df['split'] == 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start things off with a pretty basic model to serve as a baseline: a CountVectorizer and a LogisticRegression. We'll start with the tokenizer we developed in the exploration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def tokenizer(text):\n",
    "    return re.findall(r'[a-z0-9]+', text.lower())\n",
    "\n",
    "vect = CountVectorizer(tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', max_iter=100, tol=1e-6, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[idx_train, 'comment'].values\n",
    "X_dev = df.loc[idx_dev, 'comment'].values\n",
    "\n",
    "y_train = df.loc[idx_train, 'y'].values\n",
    "y_dev = df.loc[idx_dev, 'y'].values\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_dev_vect = vect.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8941110557768924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)\n",
    "y_pred = clf.predict(X_dev_vect)\n",
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we nearly got 90% on the dev set. Is accuracy a good metric for this problem though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25625,   625],\n",
       "       [ 2777,  3101]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     26250\n",
      "           1       0.83      0.53      0.65      5878\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     32128\n",
      "   macro avg       0.87      0.75      0.79     32128\n",
      "weighted avg       0.89      0.89      0.88     32128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall is pretty poor for the positive class. Let's take a look at a situation where we incorrectly classified a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed from article: \n",
      ":An extra-large common pork sausage was named after him.  \n",
      "\n",
      "Nah.  \n"
     ]
    }
   ],
   "source": [
    "idx_error = (y_dev != y_pred) & (y_dev == 1)\n",
    "print(X_dev[idx_error][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's strange, what was the average toxicity score for this instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>y</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2943468.0</td>\n",
       "      <td>Removed from article: \\n:An extra-large common...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>7258621996882801005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rev_id                                            comment  year  \\\n",
       "445  2943468.0  Removed from article: \\n:An extra-large common...  2003   \n",
       "\n",
       "     logged_in       ns  sample split  min  max  avg  y                 hash  \n",
       "445          1  article  random   dev -1.0  1.0 -0.1  1  7258621996882801005  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hash'] = df['comment'].map(hash)\n",
    "df[df['hash'] == hash(X_dev[idx_error][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may indicate problems in the dataset (or how we aggregate the scores). At this point, I would normally revisit the EDA step to review the labeling function, but let's forge ahead for now. Since we have a pretty large imbalance and the positive class is low, let's use F1 as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6457725947521866"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we efficiently tune our hyperparameters? We can use GridSearchCV or RandomizedSearchCV, but we have a pre-defined dev set so we need to use some tricks to override the normal behavior. This is actually pretty standard for large-scale NLP problems. Cross-validation is preferred, but often not feasible for large datasets.\n",
    "\n",
    "```\n",
    "For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using PredefinedSplit it is possible to use these folds e.g. when searching for hyperparameters.\n",
    "\n",
    "For example, when using a validation set, set the test_fold to 0 for all samples that are part of the validation set, and to -1 for all other samples.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df_train_dev = df[df['split'].map(lambda x: x in {'train', 'dev'})].copy()\n",
    "idx = np.where(df_train_dev['split'] == 'dev', 0, -1) # See documentation above\n",
    "\n",
    "ps = PredefinedSplit(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 60 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done  60 out of  60 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__class_weight': {0: 1, 1: 2}, 'clf__l1_ratio': 0.0, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "0.7008292182987049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jking\\AppData\\Local\\Continuum\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer(tokenizer=tokenizer)),\n",
    "                 ('clf', SGDClassifier(loss='log', max_iter=10, tol=1e-6, penalty='elasticnet', random_state=seed))])\n",
    "param_grid = {'vect__ngram_range':[(1,1), (1,2)], 'vect__min_df':[1, 2, 5, 10, 20],\n",
    "              'clf__l1_ratio':[0.0, 0.1, 0.2], 'clf__class_weight':[{0:1,1:1}, {0:1,1:2}]}\n",
    "gs = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=6, cv=ps, verbose=2)\n",
    "gs.fit(df_train_dev['comment'].values, df_train_dev['y'].values)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this step took so long, I am going to persist the result sto disk using joblib (cooking-show style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "\n",
    "# dump(gs, '../results/gs_cv_sgd.joblib')\n",
    "gs = load('../results/gs_cv_sgd.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25748,   502],\n",
       "       [  588,  5290]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_dev)\n",
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     26250\n",
      "           1       0.91      0.90      0.91      5878\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     32128\n",
      "   macro avg       0.95      0.94      0.94     32128\n",
      "weighted avg       0.97      0.97      0.97     32128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9660732071713147"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad result! Let's see if adding a TfidfTransformer can make a difference. Remember, TFIDF will reduce the impact of high-frequency words and increase the impact of rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 60 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__class_weight': {0: 1, 1: 2}, 'clf__l1_ratio': 0.0, 'vect__min_df': 20, 'vect__ngram_range': (1, 1)}\n",
      "0.6791372399312846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(tokenizer=tokenizer)),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', SGDClassifier(loss='log', max_iter=10, tol=1e-6, penalty='elasticnet', n_jobs=2, random_state=seed))])\n",
    "param_grid = {'vect__ngram_range':[(1,1), (1,2)], 'vect__min_df':[1, 2, 5, 10, 20],\n",
    "              'clf__l1_ratio':[0.0, 0.1, 0.2], 'clf__class_weight':[{0:1,1:1}, {0:1,1:2}]}\n",
    "gs = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=4, cv=ps, verbose=2)\n",
    "gs.fit(df_train_dev['comment'].values, df_train_dev['y'].values)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's store the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/gs_cv_tfidf_sgd.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(gs, '../results/gs_cv_tfidf_sgd.joblib')\n",
    "gs = load('../results/gs_cv_tfidf_sgd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25284,   966],\n",
       "       [ 2282,  3596]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_dev)\n",
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     26250\n",
      "           1       0.79      0.61      0.69      5878\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     32128\n",
      "   macro avg       0.85      0.79      0.81     32128\n",
      "weighted avg       0.89      0.90      0.89     32128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989043824701195"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So not quite as good. Now let's put together a model that uses character ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' h': 221,\n",
       " 'hi': 1838,\n",
       " 'is': 2104,\n",
       " 's ': 3376,\n",
       " ' hi': 236,\n",
       " 'his': 1857,\n",
       " 'is ': 2105,\n",
       " ' his': 241,\n",
       " 'his ': 1858,\n",
       " ' n': 347,\n",
       " 'ne': 2532,\n",
       " 'e ': 1305,\n",
       " ' ne': 357,\n",
       " 'ne ': 2533,\n",
       " ' ne ': 358,\n",
       " ' c': 82,\n",
       " 'ca': 1026,\n",
       " 'an': 773,\n",
       " 'n ': 2488,\n",
       " ' ca': 83,\n",
       " 'can': 1035,\n",
       " 'an ': 774,\n",
       " ' can': 85,\n",
       " 'can ': 1036,\n",
       " ' m': 318,\n",
       " 'ma': 2383,\n",
       " 'ak': 727,\n",
       " 'ke': 2193,\n",
       " ' ma': 320,\n",
       " 'mak': 2390,\n",
       " 'ake': 728,\n",
       " 'ke ': 2194,\n",
       " ' mak': 323,\n",
       " 'make': 2391,\n",
       " 'ake ': 729,\n",
       " ' a': 0,\n",
       " ' an': 26,\n",
       " ' an ': 27,\n",
       " 'na': 2492,\n",
       " 'al': 733,\n",
       " 'lo': 2341,\n",
       " 'og': 2730,\n",
       " 'gy': 1787,\n",
       " 'y ': 4064,\n",
       " 'ana': 775,\n",
       " 'nal': 2493,\n",
       " 'alo': 753,\n",
       " 'log': 2342,\n",
       " 'ogy': 2738,\n",
       " 'gy ': 1788,\n",
       " ' ana': 28,\n",
       " 'anal': 776,\n",
       " 'nalo': 2495,\n",
       " 'alog': 754,\n",
       " 'logy': 2344,\n",
       " 'ogy ': 2739,\n",
       " ' i': 248,\n",
       " 'in': 2028,\n",
       " ' in': 265,\n",
       " 'in ': 2029,\n",
       " ' in ': 266,\n",
       " 'at': 886,\n",
       " 'th': 3632,\n",
       " 'he': 1812,\n",
       " 'em': 1437,\n",
       " 'ti': 3656,\n",
       " 'ic': 1926,\n",
       " 'l ': 2223,\n",
       " 'mat': 2398,\n",
       " 'ath': 894,\n",
       " 'the': 3637,\n",
       " 'hem': 1818,\n",
       " 'ema': 1439,\n",
       " 'ati': 898,\n",
       " 'tic': 3658,\n",
       " 'ica': 1928,\n",
       " 'cal': 1031,\n",
       " 'al ': 734,\n",
       " ' mat': 325,\n",
       " 'math': 2400,\n",
       " 'athe': 896,\n",
       " 'them': 3640,\n",
       " 'hema': 1820,\n",
       " 'emat': 1440,\n",
       " 'mati': 2401,\n",
       " 'atic': 899,\n",
       " 'tica': 3660,\n",
       " 'ical': 1929,\n",
       " 'cal ': 1032,\n",
       " ' t': 538,\n",
       " 'te': 3611,\n",
       " 'er': 1514,\n",
       " 'rm': 3266,\n",
       " 'ms': 2479,\n",
       " ' te': 546,\n",
       " 'ter': 3625,\n",
       " 'erm': 1540,\n",
       " 'rms': 3272,\n",
       " 'ms ': 2480,\n",
       " ' ter': 548,\n",
       " 'term': 3629,\n",
       " 'erms': 1542,\n",
       " 'rms ': 3273,\n",
       " ' b': 55,\n",
       " 'by': 1023,\n",
       " ' by': 80,\n",
       " 'by ': 1024,\n",
       " ' by ': 81,\n",
       " ' e': 142,\n",
       " 'en': 1452,\n",
       " 'nv': 2677,\n",
       " 'vi': 3953,\n",
       " 'si': 3442,\n",
       " 'io': 2070,\n",
       " 'on': 2776,\n",
       " 'ni': 2583,\n",
       " 'ng': 2562,\n",
       " 'g ': 1715,\n",
       " ' en': 159,\n",
       " 'env': 1484,\n",
       " 'nvi': 2680,\n",
       " 'vis': 3968,\n",
       " 'isi': 2117,\n",
       " 'sio': 3458,\n",
       " 'ion': 2073,\n",
       " 'oni': 2797,\n",
       " 'nin': 2587,\n",
       " 'ing': 2048,\n",
       " 'ng ': 2563,\n",
       " ' env': 166,\n",
       " 'envi': 1485,\n",
       " 'nvis': 2682,\n",
       " 'visi': 3969,\n",
       " 'isio': 2119,\n",
       " 'sion': 3459,\n",
       " 'ioni': 2077,\n",
       " 'onin': 2799,\n",
       " 'ning': 2588,\n",
       " 'ing ': 2049,\n",
       " ' th': 549,\n",
       " 'he ': 1813,\n",
       " ' the': 551,\n",
       " 'the ': 3638,\n",
       " ' d': 114,\n",
       " 'di': 1240,\n",
       " 'st': 3519,\n",
       " 'tr': 3712,\n",
       " 'ri': 3216,\n",
       " 'ib': 1918,\n",
       " 'bu': 1003,\n",
       " 'ut': 3912,\n",
       " ' di': 129,\n",
       " 'dis': 1254,\n",
       " 'ist': 2128,\n",
       " 'str': 3536,\n",
       " 'tri': 3723,\n",
       " 'rib': 3220,\n",
       " 'ibu': 1924,\n",
       " 'but': 1015,\n",
       " 'uti': 3922,\n",
       " 'tio': 3673,\n",
       " 'on ': 2777,\n",
       " ' dis': 132,\n",
       " 'dist': 1257,\n",
       " 'istr': 2132,\n",
       " 'stri': 3539,\n",
       " 'trib': 3724,\n",
       " 'ribu': 3223,\n",
       " 'ibut': 1925,\n",
       " 'buti': 1018,\n",
       " 'utio': 3923,\n",
       " 'tion': 3674,\n",
       " 'ion ': 2074,\n",
       " ' o': 374,\n",
       " 'of': 2724,\n",
       " 'f ': 1641,\n",
       " ' of': 382,\n",
       " 'of ': 2725,\n",
       " ' of ': 383,\n",
       " 'op': 2825,\n",
       " 'pi': 3010,\n",
       " 'ns': 2628,\n",
       " ' op': 398,\n",
       " 'opi': 2832,\n",
       " 'pin': 3013,\n",
       " 'ini': 2053,\n",
       " 'nio': 2589,\n",
       " 'ons': 2808,\n",
       " 'ns ': 2629,\n",
       " ' opi': 399,\n",
       " 'opin': 2833,\n",
       " 'pini': 3014,\n",
       " 'inio': 2054,\n",
       " 'nion': 2590,\n",
       " 'ions': 2078,\n",
       " 'ons ': 2809,\n",
       " 'a ': 647,\n",
       " ' a ': 1,\n",
       " ' p': 423,\n",
       " 'po': 3034,\n",
       " 'pu': 3083,\n",
       " 'ul': 3835,\n",
       " 'la': 2224,\n",
       " ' po': 441,\n",
       " 'pop': 3046,\n",
       " 'opu': 2840,\n",
       " 'pul': 3086,\n",
       " 'ula': 3837,\n",
       " 'lat': 2239,\n",
       " ' pop': 447,\n",
       " 'popu': 3047,\n",
       " 'opul': 2841,\n",
       " 'pula': 3087,\n",
       " 'ulat': 3839,\n",
       " 'lati': 2242,\n",
       " 'atio': 900,\n",
       " 'as': 868,\n",
       " ' as': 44,\n",
       " 'as ': 869,\n",
       " ' as ': 45,\n",
       " 'au': 905,\n",
       " 'us': 3890,\n",
       " 'ss': 3505,\n",
       " 'ia': 1906,\n",
       " ' au': 51,\n",
       " 'aus': 909,\n",
       " 'uss': 3903,\n",
       " 'ssi': 3513,\n",
       " 'sia': 3443,\n",
       " 'ian': 1913,\n",
       " ' aus': 52,\n",
       " 'auss': 911,\n",
       " 'ussi': 3906,\n",
       " 'ssia': 3514,\n",
       " 'sian': 3444,\n",
       " 'ian ': 1914,\n",
       " 'cu': 1171,\n",
       " 'ur': 3873,\n",
       " 'rv': 3363,\n",
       " 've': 3939,\n",
       " ' cu': 111,\n",
       " 'cur': 1172,\n",
       " 'urv': 3888,\n",
       " 'rve': 3364,\n",
       " 've ': 3940,\n",
       " ' cur': 112,\n",
       " 'curv': 1173,\n",
       " 'urve': 3889,\n",
       " 'rve ': 3365,\n",
       " ' e ': 143,\n",
       " ' w': 603,\n",
       " 'wo': 4021,\n",
       " 'ou': 2916,\n",
       " 'ld': 2244,\n",
       " 'd ': 1181,\n",
       " ' wo': 623,\n",
       " 'wou': 4028,\n",
       " 'oul': 2922,\n",
       " 'uld': 3840,\n",
       " 'ld ': 2245,\n",
       " ' wou': 626,\n",
       " 'woul': 4029,\n",
       " 'ould': 2923,\n",
       " 'uld ': 3841,\n",
       " 'hen': 1821,\n",
       " 'en ': 1453,\n",
       " 'then': 3641,\n",
       " 'hen ': 1822,\n",
       " ' s': 492,\n",
       " 'sa': 3377,\n",
       " 'ay': 925,\n",
       " ' sa': 494,\n",
       " 'say': 3389,\n",
       " 'ay ': 926,\n",
       " ' say': 498,\n",
       " 'say ': 3390,\n",
       " 'ha': 1790,\n",
       " 't ': 3574,\n",
       " 'tha': 3634,\n",
       " 'hat': 1807,\n",
       " 'at ': 887,\n",
       " ' tha': 550,\n",
       " 'that': 3636,\n",
       " 'hat ': 1808,\n",
       " 'co': 1119,\n",
       " 'se': 3401,\n",
       " 'su': 3546,\n",
       " ' co': 99,\n",
       " 'con': 1130,\n",
       " 'nse': 2630,\n",
       " 'sen': 3417,\n",
       " 'ens': 1470,\n",
       " 'nsu': 2643,\n",
       " 'sus': 3566,\n",
       " 'us ': 3891,\n",
       " ' con': 103,\n",
       " 'cons': 1135,\n",
       " 'onse': 2810,\n",
       " 'nsen': 2632,\n",
       " 'sens': 3418,\n",
       " 'ensu': 1472,\n",
       " 'nsus': 2644,\n",
       " 'sus ': 3567,\n",
       " 'be': 945,\n",
       " ' be': 59,\n",
       " 'be ': 946,\n",
       " ' be ': 60,\n",
       " 'ta': 3575,\n",
       " 'me': 2405,\n",
       " 'nt': 2645,\n",
       " ' st': 525,\n",
       " 'sta': 3521,\n",
       " 'tat': 3596,\n",
       " 'ate': 888,\n",
       " 'tem': 3620,\n",
       " 'eme': 1441,\n",
       " 'men': 2419,\n",
       " 'ent': 1473,\n",
       " 'nt ': 2646,\n",
       " ' sta': 526,\n",
       " 'stat': 3524,\n",
       " 'tate': 3597,\n",
       " 'atem': 892,\n",
       " 'teme': 3621,\n",
       " 'emen': 1443,\n",
       " 'ment': 2420,\n",
       " 'ent ': 1474,\n",
       " ' r': 461,\n",
       " 're': 3160,\n",
       " 'ep': 1495,\n",
       " 'pr': 3060,\n",
       " 'es': 1559,\n",
       " 'ts': 3735,\n",
       " ' re': 467,\n",
       " 'rep': 3188,\n",
       " 'epr': 1501,\n",
       " 'pre': 3061,\n",
       " 'res': 3196,\n",
       " 'ese': 1565,\n",
       " 'nts': 2670,\n",
       " 'ts ': 3736,\n",
       " ' rep': 476,\n",
       " 'repr': 3190,\n",
       " 'epre': 1502,\n",
       " 'pres': 3062,\n",
       " 'rese': 3197,\n",
       " 'esen': 1569,\n",
       " 'sent': 3419,\n",
       " 'ents': 1481,\n",
       " 'nts ': 2671,\n",
       " 'ra': 3108,\n",
       " 'ge': 1723,\n",
       " ' ra': 462,\n",
       " 'ran': 3120,\n",
       " 'ang': 784,\n",
       " 'nge': 2564,\n",
       " 'ge ': 1724,\n",
       " ' ran': 464,\n",
       " 'rang': 3121,\n",
       " 'ange': 785,\n",
       " 'nge ': 2565,\n",
       " 'wi': 4008,\n",
       " 'it': 2134,\n",
       " ' wi': 619,\n",
       " 'wit': 4017,\n",
       " 'ith': 2145,\n",
       " 'thi': 3646,\n",
       " 'hin': 1849,\n",
       " ' wit': 622,\n",
       " 'with': 4018,\n",
       " 'ithi': 2147,\n",
       " 'thin': 3647,\n",
       " 'hin ': 1850,\n",
       " 'pe': 2979,\n",
       " 'rh': 3213,\n",
       " 'ap': 812,\n",
       " 'ps': 3073,\n",
       " ' pe': 432,\n",
       " 'per': 2993,\n",
       " 'erh': 1530,\n",
       " 'rha': 3214,\n",
       " 'hap': 1801,\n",
       " 'aps': 825,\n",
       " 'ps ': 3074,\n",
       " ' per': 434,\n",
       " 'perh': 2995,\n",
       " 'erha': 1531,\n",
       " 'rhap': 3215,\n",
       " 'haps': 1802,\n",
       " 'aps ': 826,\n",
       " 'hr': 1889,\n",
       " 'ee': 1372,\n",
       " 'thr': 3652,\n",
       " 'hre': 1892,\n",
       " 'ree': 3176,\n",
       " 'ee ': 1373,\n",
       " ' thr': 554,\n",
       " 'thre': 3653,\n",
       " 'hree': 1893,\n",
       " 'ree ': 3177,\n",
       " 'nd': 2519,\n",
       " 'da': 1182,\n",
       " 'ar': 827,\n",
       " 'rd': 3150,\n",
       " 'tan': 3590,\n",
       " 'and': 779,\n",
       " 'nda': 2521,\n",
       " 'dar': 1186,\n",
       " 'ard': 836,\n",
       " 'rd ': 3151,\n",
       " 'stan': 3523,\n",
       " 'tand': 3592,\n",
       " 'anda': 781,\n",
       " 'ndar': 2523,\n",
       " 'dard': 1187,\n",
       " 'ard ': 837,\n",
       " 'de': 1199,\n",
       " 'ev': 1612,\n",
       " ' de': 118,\n",
       " 'dev': 1235,\n",
       " 'evi': 1616,\n",
       " 'via': 3954,\n",
       " 'iat': 1915,\n",
       " ' dev': 128,\n",
       " 'devi': 1236,\n",
       " 'evia': 1617,\n",
       " 'viat': 3955,\n",
       " 'iati': 1917,\n",
       " 'ea': 1306,\n",
       " ' me': 327,\n",
       " 'mea': 2407,\n",
       " 'ean': 1321,\n",
       " ' mea': 329,\n",
       " 'mean': 2408,\n",
       " 'ean ': 1322,\n",
       " 'so': 3479,\n",
       " 'un': 3853,\n",
       " 'ds': 1289,\n",
       " ' so': 515,\n",
       " 'sou': 3491,\n",
       " 'oun': 2924,\n",
       " 'und': 3855,\n",
       " 'nds': 2530,\n",
       " 'ds ': 1290,\n",
       " ' sou': 520,\n",
       " 'soun': 3492,\n",
       " 'ound': 2925,\n",
       " 'unds': 3859,\n",
       " 'nds ': 2531,\n",
       " 'rb': 3141,\n",
       " 'bi': 964,\n",
       " 'ry': 3369,\n",
       " ' ar': 37,\n",
       " 'arb': 832,\n",
       " 'rbi': 3142,\n",
       " 'bit': 973,\n",
       " 'itr': 2159,\n",
       " 'tra': 3713,\n",
       " 'rar': 3126,\n",
       " 'ary': 865,\n",
       " 'ry ': 3370,\n",
       " ' arb': 38,\n",
       " 'arbi': 833,\n",
       " 'rbit': 3143,\n",
       " 'bitr': 974,\n",
       " 'itra': 2160,\n",
       " 'trar': 3718,\n",
       " 'rary': 3128,\n",
       " 'ary ': 866,\n",
       " 'nd ': 2520,\n",
       " ' and': 29,\n",
       " 'and ': 780,\n",
       " 'ad': 681,\n",
       " ' ad': 9,\n",
       " 'ad ': 682,\n",
       " ' ad ': 10,\n",
       " 'ho': 1873,\n",
       " 'oc': 2702,\n",
       " 'c ': 1025,\n",
       " ' ho': 242,\n",
       " 'hoc': 1875,\n",
       " 'oc ': 2703,\n",
       " ' hoc': 243,\n",
       " 'hoc ': 1876,\n",
       " 'oe': 2721,\n",
       " ' oe': 380,\n",
       " 'oes': 2722,\n",
       " 'es ': 1560,\n",
       " ' oes': 381,\n",
       " 'oes ': 2723,\n",
       " ' it': 278,\n",
       " 'it ': 2135,\n",
       " ' it ': 279,\n",
       " 'll': 2320,\n",
       " 'ly': 2378,\n",
       " 'rea': 3162,\n",
       " 'eal': 1314,\n",
       " 'all': 746,\n",
       " 'lly': 2337,\n",
       " 'ly ': 2379,\n",
       " ' rea': 469,\n",
       " 'real': 3165,\n",
       " 'eall': 1317,\n",
       " 'ally': 750,\n",
       " 'lly ': 2338,\n",
       " 'el': 1418,\n",
       " 'bel': 954,\n",
       " 'elo': 1433,\n",
       " 'lon': 2345,\n",
       " 'ong': 2794,\n",
       " ' bel': 64,\n",
       " 'belo': 956,\n",
       " 'elon': 1434,\n",
       " 'long': 2346,\n",
       " 'ong ': 2795,\n",
       " ' n ': 348,\n",
       " 'nc': 2504,\n",
       " 'cy': 1177,\n",
       " 'yc': 4068,\n",
       " 'cl': 1107,\n",
       " 'ed': 1366,\n",
       " 'enc': 1454,\n",
       " 'ncy': 2517,\n",
       " 'cyc': 1179,\n",
       " 'ycl': 4069,\n",
       " 'clo': 1114,\n",
       " 'lop': 2347,\n",
       " 'ope': 2828,\n",
       " 'ped': 2986,\n",
       " 'edi': 1368,\n",
       " 'dia': 1241,\n",
       " 'ia ': 1907,\n",
       " ' enc': 160,\n",
       " 'ency': 1457,\n",
       " 'ncyc': 2518,\n",
       " 'cycl': 1180,\n",
       " 'yclo': 4070,\n",
       " 'clop': 1115,\n",
       " 'lope': 2348,\n",
       " 'oped': 2830,\n",
       " 'pedi': 2987,\n",
       " 'edia': 1369,\n",
       " 'dia ': 1242,\n",
       " 'rt': 3338,\n",
       " 'le': 2254,\n",
       " 'art': 861,\n",
       " 'rti': 3345,\n",
       " 'icl': 1939,\n",
       " 'cle': 1110,\n",
       " 'le ': 2255,\n",
       " ' art': 43,\n",
       " 'arti': 863,\n",
       " 'rtic': 3346,\n",
       " 'ticl': 3661,\n",
       " 'icle': 1940,\n",
       " 'cle ': 1111,\n",
       " 'do': 1274,\n",
       " ' do': 133,\n",
       " 'don': 1278,\n",
       " ' don': 136,\n",
       " 'don ': 1279,\n",
       " ' t ': 539,\n",
       " ' se': 501,\n",
       " 'see': 3408,\n",
       " ' see': 502,\n",
       " 'see ': 3409,\n",
       " 'dd': 1192,\n",
       " 'add': 683,\n",
       " 'dds': 1197,\n",
       " ' add': 11,\n",
       " 'adds': 685,\n",
       " 'dds ': 1198,\n",
       " 'ny': 2683,\n",
       " 'yt': 4098,\n",
       " 'any': 807,\n",
       " 'nyt': 2687,\n",
       " 'yth': 4099,\n",
       " ' any': 33,\n",
       " 'anyt': 810,\n",
       " 'nyth': 2688,\n",
       " 'ythi': 4100,\n",
       " 'hing': 1853,\n",
       " ' u': 572,\n",
       " 'ef': 1388,\n",
       " 'fu': 1707,\n",
       " ' us': 581,\n",
       " 'use': 3894,\n",
       " 'sef': 3411,\n",
       " 'efu': 1395,\n",
       " 'ful': 1708,\n",
       " 'ul ': 3836,\n",
       " ' use': 584,\n",
       " 'usef': 3897,\n",
       " 'sefu': 3412,\n",
       " 'eful': 1396,\n",
       " 'ful ': 1709,\n",
       " ' he': 231,\n",
       " ' he ': 232,\n",
       " 'pa': 2957,\n",
       " 'ag': 701,\n",
       " 'gr': 1765,\n",
       " 'ph': 3001,\n",
       " 'h ': 1789,\n",
       " ' pa': 424,\n",
       " 'par': 2971,\n",
       " 'ara': 829,\n",
       " 'rag': 3112,\n",
       " 'agr': 711,\n",
       " 'gra': 1766,\n",
       " 'rap': 3124,\n",
       " 'aph': 818,\n",
       " 'ph ': 3002,\n",
       " ' par': 430,\n",
       " 'para': 2972,\n",
       " 'arag': 830,\n",
       " 'ragr': 3113,\n",
       " 'agra': 712,\n",
       " 'grap': 1767,\n",
       " 'raph': 3125,\n",
       " 'aph ': 819,\n",
       " ' f': 186,\n",
       " 'fo': 1689,\n",
       " 'ol': 2743,\n",
       " 'ow': 2944,\n",
       " 'ws': 4036,\n",
       " ' fo': 202,\n",
       " 'fol': 1690,\n",
       " 'oll': 2754,\n",
       " 'llo': 2332,\n",
       " 'low': 2351,\n",
       " 'ows': 2951,\n",
       " 'ws ': 4037,\n",
       " ' fol': 203,\n",
       " 'foll': 1691,\n",
       " 'ollo': 2756,\n",
       " 'llow': 2334,\n",
       " 'lows': 2353,\n",
       " 'ows ': 2952,\n",
       " 'eem': 1378,\n",
       " 'ems': 1450,\n",
       " 'seem': 3410,\n",
       " 'eems': 1380,\n",
       " 'ems ': 1451,\n",
       " 'mu': 2481,\n",
       " 'uc': 3781,\n",
       " 'ch': 1073,\n",
       " ' mu': 342,\n",
       " 'muc': 2482,\n",
       " 'uch': 3782,\n",
       " 'ch ': 1074,\n",
       " ' muc': 343,\n",
       " 'much': 2483,\n",
       " 'uch ': 3783,\n",
       " 'mo': 2451,\n",
       " 'or': 2846,\n",
       " ' mo': 337,\n",
       " 'mor': 2457,\n",
       " 'ore': 2856,\n",
       " 're ': 3161,\n",
       " ' mor': 340,\n",
       " 'more': 2459,\n",
       " 'ore ': 2857,\n",
       " ' re ': 468,\n",
       " 'her': 1825,\n",
       " 'ere': 1522,\n",
       " 'ther': 3643,\n",
       " 'here': 1827,\n",
       " 'ere ': 1523,\n",
       " 'ny ': 2684,\n",
       " 'any ': 808,\n",
       " 'li': 2288,\n",
       " 'pol': 3039,\n",
       " 'oli': 2751,\n",
       " 'lit': 2311,\n",
       " 'iti': 2149,\n",
       " ' pol': 444,\n",
       " 'poli': 3040,\n",
       " 'olit': 2753,\n",
       " 'liti': 2313,\n",
       " 'itic': 2150,\n",
       " 'eo': 1486,\n",
       " 'heo': 1823,\n",
       " 'eor': 1492,\n",
       " 'ori': 2861,\n",
       " 'ris': 3245,\n",
       " 'sts': 3540,\n",
       " 'theo': 3642,\n",
       " 'heor': 1824,\n",
       " 'eori': 1493,\n",
       " 'oris': 2865,\n",
       " 'rist': 3247,\n",
       " 'ists': 2133,\n",
       " 'sts ': 3541,\n",
       " ' ou': 413,\n",
       " 'out': 2936,\n",
       " 'ut ': 3913,\n",
       " ' out': 416,\n",
       " 'out ': 2937,\n",
       " 'wh': 3995,\n",
       " 'o ': 2691,\n",
       " ' wh': 613,\n",
       " 'who': 4004,\n",
       " 'ho ': 1874,\n",
       " ' who': 617,\n",
       " 'who ': 4005,\n",
       " 'if': 1975,\n",
       " 'fy': 1713,\n",
       " ' cl': 96,\n",
       " 'cla': 1108,\n",
       " 'lar': 2234,\n",
       " 'ari': 847,\n",
       " 'rif': 3232,\n",
       " 'ify': 1982,\n",
       " 'fy ': 1714,\n",
       " ' cla': 97,\n",
       " 'clar': 1109,\n",
       " 'lari': 2235,\n",
       " 'arif': 848,\n",
       " 'rify': 3234,\n",
       " 'ify ': 1983,\n",
       " 'ue': 3796,\n",
       " ' is': 274,\n",
       " 'iss': 2126,\n",
       " 'ssu': 3516,\n",
       " 'sue': 3553,\n",
       " 'ues': 3800,\n",
       " ' iss': 277,\n",
       " 'issu': 2127,\n",
       " 'ssue': 3517,\n",
       " 'sues': 3555,\n",
       " 'ues ': 3801,\n",
       " 'to': 3693,\n",
       " ' to': 558,\n",
       " 'to ': 3694,\n",
       " ' to ': 559,\n",
       " 'me ': 2406,\n",
       " ' me ': 328,\n",
       " ' thi': 552,\n",
       " 'this': 3648,\n",
       " ' is ': 275,\n",
       " 'ue ': 3797,\n",
       " 'sue ': 3554,\n",
       " 'ck': 1097,\n",
       " ' oc': 378,\n",
       " 'ock': 2710,\n",
       " 'cke': 1101,\n",
       " ' ock': 379,\n",
       " 'ocke': 2711,\n",
       " 'cke ': 1102,\n",
       " 'u ': 3761,\n",
       " 'ous': 2932,\n",
       " 'sse': 3509,\n",
       " 'sea': 3403,\n",
       " 'eau': 1337,\n",
       " 'au ': 906,\n",
       " ' ous': 415,\n",
       " 'ouss': 2935,\n",
       " 'usse': 3905,\n",
       " 'ssea': 3510,\n",
       " 'seau': 3405,\n",
       " 'eau ': 1338,\n",
       " 'de ': 1200,\n",
       " ' de ': 119,\n",
       " 'oq': 2842,\n",
       " 'qu': 3096,\n",
       " 'il': 1997,\n",
       " ' oq': 401,\n",
       " 'oqu': 2843,\n",
       " 'que': 3097,\n",
       " 'uev': 3803,\n",
       " 'vil': 3960,\n",
       " 'ill': 2007,\n",
       " 'lle': 2324,\n",
       " ' oqu': 402,\n",
       " 'oque': 2844,\n",
       " 'quev': 3099,\n",
       " 'uevi': 3804,\n",
       " 'evil': 1619,\n",
       " 'vill': 3961,\n",
       " 'ille': 2009,\n",
       " 'lle ': 2325,\n",
       " 'ot': 2898,\n",
       " 'rs': 3327,\n",
       " ' ot': 409,\n",
       " 'oth': 2907,\n",
       " 'ers': 1547,\n",
       " 'rs ': 3328,\n",
       " ' oth': 412,\n",
       " 'othe': 2909,\n",
       " 'hers': 1829,\n",
       " 'ers ': 1548,\n",
       " 'mus': 2484,\n",
       " 'ust': 3907,\n",
       " 'st ': 3520,\n",
       " ' mus': 344,\n",
       " 'must': 2485,\n",
       " 'ust ': 3908,\n",
       " 'av': 912,\n",
       " ' ha': 223,\n",
       " 'hav': 1809,\n",
       " 'ave': 913,\n",
       " ' hav': 230,\n",
       " 'have': 1810,\n",
       " 'ave ': 914,\n",
       " 'eb': 1339,\n",
       " 'ba': 933,\n",
       " 'deb': 1203,\n",
       " 'eba': 1340,\n",
       " 'bat': 940,\n",
       " 'ted': 3615,\n",
       " 'ed ': 1367,\n",
       " ' deb': 120,\n",
       " 'deba': 1204,\n",
       " 'ebat': 1341,\n",
       " 'bate': 941,\n",
       " 'ated': 890,\n",
       " 'ted ': 3616,\n",
       " ' l': 291,\n",
       " 'fi': 1666,\n",
       " ' la': 292,\n",
       " 'ifi': 1979,\n",
       " 'fic': 1667,\n",
       " 'cat': 1047,\n",
       " ' lar': 296,\n",
       " 'rifi': 3233,\n",
       " 'ific': 1980,\n",
       " 'fica': 1669,\n",
       " 'icat': 1931,\n",
       " 'cati': 1049,\n",
       " 'r ': 3107,\n",
       " 'for': 1692,\n",
       " 'or ': 2847,\n",
       " ' for': 204,\n",
       " 'for ': 1693,\n",
       " ' y': 635,\n",
       " 'yo': 4085,\n",
       " ' yo': 637,\n",
       " 'you': 4088,\n",
       " 'ou ': 2917,\n",
       " ' you': 638,\n",
       " 'you ': 4089,\n",
       " 'rk': 3257,\n",
       " 'k ': 2188,\n",
       " ' un': 575,\n",
       " 'ark': 850,\n",
       " 'rk ': 3258,\n",
       " ' und': 576,\n",
       " 'unda': 3857,\n",
       " 'dark': 1188,\n",
       " 'ark ': 851,\n",
       " ' s ': 493,\n",
       " 'ig': 1984,\n",
       " 'gh': 1738,\n",
       " 'ht': 1894,\n",
       " ' ri': 480,\n",
       " 'rig': 3235,\n",
       " 'igh': 1988,\n",
       " 'ght': 1744,\n",
       " 'ht ': 1895,\n",
       " ' rig': 482,\n",
       " 'righ': 3236,\n",
       " 'ight': 1990,\n",
       " 'ght ': 1745,\n",
       " 'i ': 1905,\n",
       " ' i ': 249,\n",
       " 'sh': 3428,\n",
       " ' sh': 506,\n",
       " 'sho': 3440,\n",
       " 'hou': 1885,\n",
       " ' sho': 508,\n",
       " 'shou': 3441,\n",
       " 'houl': 1887,\n",
       " 'ec': 1344,\n",
       " ' ch': 91,\n",
       " 'che': 1077,\n",
       " 'hec': 1814,\n",
       " 'eck': 1356,\n",
       " 'ked': 2195,\n",
       " ' che': 92,\n",
       " 'chec': 1078,\n",
       " 'heck': 1815,\n",
       " 'ecke': 1357,\n",
       " 'cked': 1103,\n",
       " 'ked ': 2196,\n",
       " 'ik': 1991,\n",
       " 'ki': 2212,\n",
       " 'ip': 2083,\n",
       " ' ik': 260,\n",
       " 'iki': 1995,\n",
       " 'kip': 2215,\n",
       " 'ipe': 2084,\n",
       " ' iki': 261,\n",
       " 'ikip': 1996,\n",
       " 'kipe': 2216,\n",
       " 'iped': 2085,\n",
       " 'ug': 3808,\n",
       " 'gs': 1775,\n",
       " ' bu': 74,\n",
       " 'bug': 1004,\n",
       " 'ugs': 3817,\n",
       " 'gs ': 1776,\n",
       " ' bug': 75,\n",
       " 'bugs': 1006,\n",
       " 'ugs ': 3818,\n",
       " 'pag': 2961,\n",
       " 'age': 705,\n",
       " ' pag': 426,\n",
       " 'page': 2962,\n",
       " 'age ': 706,\n",
       " 'ir': 2092,\n",
       " ' fi': 193,\n",
       " 'fir': 1681,\n",
       " 'irs': 2100,\n",
       " 'rst': 3335,\n",
       " ' fir': 198,\n",
       " 'firs': 1682,\n",
       " 'irst': 2101,\n",
       " 'rst ': 3336,\n",
       " 'ug ': 3809,\n",
       " 'bug ': 1005,\n",
       " 'od': 2712,\n",
       " 'cod': 1120,\n",
       " 'ode': 2713,\n",
       " ' cod': 100,\n",
       " 'code': 1121,\n",
       " 'ode ': 2714,\n",
       " 'kes': 2205,\n",
       " 'akes': 732,\n",
       " 'kes ': 2206,\n",
       " 'wik': 4009,\n",
       " ' wik': 620,\n",
       " 'wiki': 4010,\n",
       " 'wor': 4024,\n",
       " 'ork': 2866,\n",
       " ' wor': 625,\n",
       " 'work': 4026,\n",
       " 'ork ': 2867,\n",
       " ' j': 281,\n",
       " 'ju': 2185,\n",
       " ' ju': 284,\n",
       " 'jus': 2186,\n",
       " ' jus': 285,\n",
       " 'just': 2187,\n",
       " 'ans': 796,\n",
       " 'eans': 1324,\n",
       " 'ans ': 797,\n",
       " ' li': 305,\n",
       " 'lin': 2304,\n",
       " 'ine': 2039,\n",
       " ' lin': 309,\n",
       " 'line': 2305,\n",
       " 'ine ': 2040,\n",
       " 'may': 2402,\n",
       " ' may': 326,\n",
       " 'may ': 2403,\n",
       " 'rr': 3317,\n",
       " 'ro': 3276,\n",
       " ' er': 169,\n",
       " 'err': 1545,\n",
       " 'rro': 3323,\n",
       " 'ror': 3302,\n",
       " ' err': 171,\n",
       " 'erro': 1546,\n",
       " 'rror': 3324,\n",
       " 'ror ': 3303,\n",
       " 'sm': 3473,\n",
       " ' sm': 513,\n",
       " 'sma': 3475,\n",
       " 'mal': 2392,\n",
       " 'll ': 2321,\n",
       " ' sma': 514,\n",
       " 'smal': 3476,\n",
       " 'mall': 2393,\n",
       " 'all ': 747,\n",
       " 'ex': 1628,\n",
       " 'xt': 4061,\n",
       " ' ex': 182,\n",
       " 'ext': 1637,\n",
       " 'xtr': 4062,\n",
       " 'ra ': 3109,\n",
       " ' ext': 185,\n",
       " 'extr': 1638,\n",
       " 'xtra': 4063,\n",
       " 'tra ': 3714,\n",
       " 'sp': 3494,\n",
       " 'ac': 662,\n",
       " 'ce': 1058,\n",
       " ' sp': 521,\n",
       " 'spa': 3495,\n",
       " 'pac': 2958,\n",
       " 'ace': 668,\n",
       " 'ce ': 1059,\n",
       " ' spa': 522,\n",
       " 'spac': 3496,\n",
       " 'pace': 2959,\n",
       " 'ace ': 669,\n",
       " 'go': 1761,\n",
       " 'ogo': 2733,\n",
       " 'gou': 1763,\n",
       " 'logo': 2343,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_junk(text):\n",
    "    return ' '.join(re.findall(r'[a-z0-9]+', text))\n",
    "\n",
    "vect = CountVectorizer(preprocessor=strip_junk, analyzer='char_wb', ngram_range=(2,4))\n",
    "\n",
    "vect.fit(X_train[:10])\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that char_wb pads the beginning and end of the ngram with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95692x114053 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41360832 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_dev_vect = vect.transform(X_dev)\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24777,  1473],\n",
       "       [ 2457,  3421]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', max_iter=100, tol=1e-6, random_state=seed)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "y_pred = clf.predict(X_dev_vect)\n",
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     26250\n",
      "           1       0.70      0.58      0.64      5878\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     32128\n",
      "   macro avg       0.80      0.76      0.78     32128\n",
      "weighted avg       0.87      0.88      0.87     32128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776767928286853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result isn't great, but it isn't terrible either. Let's try a little tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 54 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed: 39.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__class_weight': {0: 1, 1: 2}, 'clf__l1_ratio': 0.2, 'vect__min_df': 5, 'vect__ngram_range': (2, 5)}\n",
      "0.626993654604699\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer(preprocessor=strip_junk, analyzer='char_wb', ngram_range=(2,4))),\n",
    "                 ('clf', SGDClassifier(loss='log', max_iter=10, tol=1e-6, penalty='elasticnet', n_jobs=2, random_state=seed))])\n",
    "param_grid = {'vect__ngram_range':[(2,3), (2,4), (2,5)], 'vect__min_df':[1, 2, 5],\n",
    "              'clf__l1_ratio':[0.0, 0.1, 0.2], 'clf__class_weight':[{0:1,1:1}, {0:1,1:2}]}\n",
    "gs = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=4, cv=ps, verbose=2)\n",
    "gs.fit(df_train_dev['comment'].values, df_train_dev['y'].values)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/gs_cv__char_wb_sgd.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(gs, '../results/gs_cv__char_wb_sgd.joblib')\n",
    "gs = load('../results/gs_cv__char_wb_sgd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22009,  4241],\n",
       "       [ 1246,  4632]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_dev)\n",
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89     26250\n",
      "           1       0.52      0.79      0.63      5878\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     32128\n",
      "   macro avg       0.73      0.81      0.76     32128\n",
      "weighted avg       0.87      0.83      0.84     32128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8292143924302788"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
